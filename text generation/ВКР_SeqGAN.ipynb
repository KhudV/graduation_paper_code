{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhudV/graduation_paper_code/blob/main/text%20generation/%D0%92%D0%9A%D0%A0_SeqGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSAtCAGcQgJP"
      },
      "source": [
        "**Выборка данных:**\n",
        ">*    Dataset: NetFlix Shows. Этот набор данных содержит непомеченные текстовые данные около 9000 шоу и фильмов Netflix, а также полную информацию, такую как актерский состав, год выпуска, рейтинг, описание и т. д.\n",
        "\n",
        "**Описание работы:**\n",
        "> В данной работе проведены реализация, обучение и тестирование нейронных сетей для генерации текстов. Используются такие нейросетевые модели как LSTM и SeqGAN. Проведена оценка качества генерации текста с помощью метрики BLEU.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mRG9mlM3z69"
      },
      "source": [
        "Подключение к Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzB9Qsf7QeUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef4a42d6-3887-4406-a606-7e83e1a0bb21"
      },
      "source": [
        "#подключение к гугл диску\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqRu97X9S9A9"
      },
      "source": [
        "import os\n",
        "\n",
        "path = '/content/drive/My Drive/ВКР/SeqGAN/'\n",
        "os.chdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CInBwn4iUsK7"
      },
      "source": [
        "Объявление параметров по умолчанию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbtQOz8UUn0Q"
      },
      "source": [
        "from __future__ import print_function\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.autograd as autograd\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "\n",
        "import helpers # из Yu L. et al.\n",
        "\n",
        "CUDA = False # использование cuda (gpu/tpu): True/False\n",
        "BATCH_SIZE = 100 # количество примеров в батче\n",
        "MLE_TRAIN_EPOCHS = 30 # количество эпох при обучении генератора на основе MLE\n",
        "DIS_TRAIN_ITERATIONS = 300 # количество итераций при обучении дискриминатора\n",
        "DIS_TRAIN_EPOCHS = 1 # количество эпох в одной итерации обучения дискриминатора\n",
        "ADV_TRAIN_EPOCHS = 25 # количество эпох при обучении генератора на основе состязательного обучения / обучения с подкреплением\n",
        "POS_NEG_SAMPLES = 1000\n",
        "\n",
        "GEN_EMBEDDING_DIM = 150 # ширина слоя Embedding генератора\n",
        "GEN_HIDDEN_DIM = 150 # количество нейронов в слоях генератора\n",
        "DIS_EMBEDDING_DIM = 150 # ширина слоя Embedding дискриминатора\n",
        "DIS_HIDDEN_DIM = 150 # количество нейронов в слоях дискриминатора\n",
        "\n",
        "# параметры START_LETTER, VOCAB_SIZE, MAX_SEQ_LEN и FILE_PATHS задаются ниже\n",
        "START_LETTER = 0 #! стартовое слово\n",
        "MAX_SEQ_LEN = 24 # длина генерируемого примера\n",
        "VOCAB_SIZE = 20662 # количество слов в словаре\n",
        "FILE_PATHS = {'train': r'datasets/netflix_titles_train.txt', 'test': r'datasets/netflix_titles_test.txt',\n",
        "              'vocab': r'datasets/netflix_titles_vocab.pkl', 'saved_models': r'saved_models/netflix_titles'} # пути к файлам набора данных\n",
        "CLOSING_WORD = 20661 # заключительное слово / слово заполнитель ставящееся в конце предложения"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nZvyD7AVMWl"
      },
      "source": [
        "Инициализация генераторов случайных чисел."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXQAcf0yVL6Q"
      },
      "source": [
        "torch.random.manual_seed(66)\n",
        "np.random.seed(66)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D22oWzXQ3-A-"
      },
      "source": [
        "Объявление класса Генератора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWxd3fgqvLbz"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, gpu=False):\n",
        "    super(Generator, self).__init__()\n",
        "    self.hidden_dim = hidden_dim # количество элементов на скрытом слое\n",
        "    self.embedding_dim = embedding_dim # размер слоя embedding\n",
        "    self.max_seq_len = max_seq_len # длина генерируемых примеров\n",
        "    self.vocab_size = vocab_size # размер словаря использующегося при генерации\n",
        "    self.gpu = gpu # использование cuda (True/False)\n",
        "    self.lstm_num_layers = 1 # количество LSTM слоев\n",
        "\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim) # объявление слоя embeddings\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=self.lstm_num_layers) # объявление LSTM слоев\n",
        "    self.lstm2out = nn.Linear(hidden_dim, vocab_size) # объявление выходного слоя\n",
        "\n",
        "  def init_hidden(self, batch_size=1):\n",
        "    # инициализация состояния LSTM слоев\n",
        "    h = autograd.Variable(torch.zeros(self.lstm_num_layers, batch_size, self.hidden_dim)) \n",
        "    c = autograd.Variable(torch.zeros(self.lstm_num_layers, batch_size, self.hidden_dim))\n",
        "\n",
        "    if self.gpu:\n",
        "        return h.cuda(), c.cuda()\n",
        "    else:\n",
        "        return h, c\n",
        "\n",
        "  def forward(self, inp, hidden, c):\n",
        "    \"\"\"\n",
        "    Embeds input and applies LSTM one token at a time (seq_len = 1)\n",
        "    \"\"\"\n",
        "    # input dim                                             # batch_size\n",
        "    emb = self.embeddings(inp)                              # batch_size x embedding_dim\n",
        "    emb = emb.view(1, -1, self.embedding_dim)               # 1 x batch_size x embedding_dim\n",
        "    out, (hidden, c) = self.lstm(emb, (hidden, c))                    # 1 x batch_size x hidden_dim (out)\n",
        "    out = self.lstm2out(out.view(-1, self.hidden_dim))       # batch_size x vocab_size\n",
        "    out = F.log_softmax(out, dim=1)\n",
        "    return out, hidden, c\n",
        "\n",
        "  def sample(self, num_samples, start_letter=0, degree=1):\n",
        "    \"\"\"\n",
        "    Samples the network and returns num_samples samples of length max_seq_len.\n",
        "\n",
        "    Outputs: samples, hidden\n",
        "        - samples: num_samples x max_seq_length (a sampled sequence in each row)\n",
        "    \"\"\"\n",
        "\n",
        "    samples = torch.zeros(num_samples, self.max_seq_len).type(torch.LongTensor)\n",
        "\n",
        "    h, c = self.init_hidden(num_samples)\n",
        "    inp = autograd.Variable(torch.LongTensor([start_letter]*num_samples))\n",
        "    if self.gpu:\n",
        "        samples = samples.cuda()\n",
        "        inp = inp.cuda()\n",
        "\n",
        "    for i in range(self.max_seq_len):\n",
        "        out, h, c = self.forward(inp, h, c)               # out: num_samples x vocab_size\n",
        "        out = torch.exp(out)**degree\n",
        "        out = torch.multinomial(out, 1)  # num_samples x 1 (sampling from each row)\n",
        "        samples[:, i] = out.view(-1).data\n",
        "\n",
        "        inp = out.view(-1)\n",
        "\n",
        "    return samples\n",
        "\n",
        "  def batchNLLLoss(self, inp, target):\n",
        "    \"\"\"\n",
        "    Returns the NLL Loss for predicting target sequence.\n",
        "\n",
        "    Inputs: inp, target\n",
        "        - inp: batch_size x seq_len\n",
        "        - target: batch_size x seq_len\n",
        "\n",
        "        inp should be target with <s> (start letter) prepended\n",
        "    \"\"\"\n",
        "\n",
        "    loss_fn = nn.NLLLoss()\n",
        "    batch_size, seq_len = inp.size()\n",
        "    inp = inp.permute(1, 0)           # seq_len x batch_size\n",
        "    target = target.permute(1, 0)     # seq_len x batch_size\n",
        "    h, c = self.init_hidden(batch_size)\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(seq_len):\n",
        "        out, h, c = self.forward(inp[i], h, c)\n",
        "        loss += loss_fn(out, target[i])\n",
        "\n",
        "    return loss     # per batch\n",
        "\n",
        "  def batchPGLoss(self, inp, target, reward):\n",
        "    \"\"\"\n",
        "    Returns a pseudo-loss that gives corresponding policy gradients (on calling .backward()).\n",
        "    Inspired by the example in http://karpathy.github.io/2016/05/31/rl/\n",
        "\n",
        "    Inputs: inp, target\n",
        "        - inp: batch_size x seq_len\n",
        "        - target: batch_size x seq_len\n",
        "        - reward: batch_size (discriminator reward for each sentence, applied to each token of the corresponding\n",
        "                  sentence)\n",
        "\n",
        "        inp should be target with <s> (start letter) prepended\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, seq_len = inp.size()\n",
        "    inp = inp.permute(1, 0)          # seq_len x batch_size\n",
        "    target = target.permute(1, 0)    # seq_len x batch_size\n",
        "    h, c = self.init_hidden(batch_size)\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(seq_len):\n",
        "        out, h, c = self.forward(inp[i], h, c)\n",
        "        # TODO: should h be detached from graph (.detach())?\n",
        "        for j in range(batch_size):\n",
        "            loss += -out[j][target.data[i][j]]*reward[j]#     # log(P(y_t|Y_1:Y_{t-1})) * Q\n",
        "\n",
        "    return loss/batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut2px_RD4HIi"
      },
      "source": [
        "Объявяление класса Дискриминатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUIXW8JMzAWk"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, gpu=False, dropout=0.2):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.hidden_dim = hidden_dim # размер скрытого слоя\n",
        "        self.embedding_dim = embedding_dim # ширина слоя embedding\n",
        "        self.max_seq_len = max_seq_len # длина входного примера\n",
        "        self.gpu = gpu # использование cuda (True/False)\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) # объявление слоя Embedding\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=3, bidirectional=True, dropout=dropout) # объявление LSTM слоев\n",
        "\n",
        "        self.lstm2hidden = nn.Linear(2*3*hidden_dim, hidden_dim) # объявление скрытого слоя\n",
        "        # self.lstm2hidden = nn.Linear(max_seq_len*hidden_dim*2, hidden_dim) # объявление скрытого слоя\n",
        "\n",
        "        self.dropout_linear = nn.Dropout(p=dropout)\n",
        "        self.hidden2out = nn.Linear(hidden_dim, 1) # объявление выходного слоя\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # инициализация LSTM слоев\n",
        "        h = autograd.Variable(torch.zeros(2*3*1, batch_size, self.hidden_dim))\n",
        "        c = autograd.Variable(torch.zeros(2*3*1, batch_size, self.hidden_dim))\n",
        "\n",
        "        if self.gpu:\n",
        "            return h.cuda(), c.cuda()\n",
        "        else:\n",
        "            return h, c\n",
        "\n",
        "    def forward(self, input, hidden, c):\n",
        "        # input dim                                                # batch_size x seq_len\n",
        "        # print(input.shape)\n",
        "        emb = self.embeddings(input)                               # batch_size x seq_len x embedding_dim\n",
        "        # print(emb.shape)\n",
        "        emb = emb.permute(1, 0, 2)                                 # seq_len x batch_size x embedding_dim\n",
        "        # print(emb.shape)\n",
        "        out_lstm, (hidden, c) = self.lstm(emb, (hidden, c))                          # 4 x batch_size x hidden_dim\n",
        "\n",
        "        hidden = hidden.permute(1, 0, 2).contiguous()              # batch_size x 4 x hidden_dim\n",
        "        # hidden = out_lstm\n",
        "        # print(hidden.shape, hidden.view(-1, self.max_seq_len*self.hidden_dim).shape)\n",
        "        # print(hidden.permute(1, 0, 2).contiguous().shape, hidden.permute(1, 0, 2).contiguous().view(-1, self.max_seq_len*self.hidden_dim*2).shape)\n",
        "\n",
        "        out = self.lstm2hidden(hidden.view(-1, 6*self.hidden_dim))  # batch_size x 4*hidden_dim\n",
        "        # out = self.lstm2hidden(hidden.view(-1, self.max_seq_len*self.hidden_dim*2))  # batch_size x 4*hidden_dim\n",
        "        \n",
        "        out = torch.relu(out)\n",
        "        # out = out * torch.sigmoid(0.1 * out) # функция активации Swish: x * sigmoid(b*x)\n",
        "        out = self.dropout_linear(out)\n",
        "        out = self.hidden2out(out)                                 # batch_size x 1\n",
        "        out = torch.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "    def batchClassify(self, inp):\n",
        "        \"\"\"\n",
        "        Classifies a batch of sequences.\n",
        "\n",
        "        Inputs: inp\n",
        "            - inp: batch_size x seq_len\n",
        "\n",
        "        Returns: out\n",
        "            - out: batch_size ([0,1] score)\n",
        "        \"\"\"\n",
        "\n",
        "        h, c = self.init_hidden(inp.size()[0])\n",
        "        out = self.forward(inp, h, c)\n",
        "        return out.view(-1)\n",
        "\n",
        "    def batchBCELoss(self, inp, target):\n",
        "        \"\"\"\n",
        "        Returns Binary Cross Entropy Loss for discriminator.\n",
        "\n",
        "         Inputs: inp, target\n",
        "            - inp: batch_size x seq_len\n",
        "            - target: batch_size (binary 1/0)\n",
        "        \"\"\"\n",
        "\n",
        "        loss_fn = nn.BCELoss()\n",
        "        h, c = self.init_hidden(inp.size()[0])\n",
        "        out = self.forward(inp, h, c)\n",
        "        return loss_fn(out, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czr-pzJe4KTW"
      },
      "source": [
        "Объявление функций возвращающих данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQ2qmEm3xZ9"
      },
      "source": [
        "# функции генерации данных\n",
        "def sampler_example(batch_size):\n",
        "  x = data_file_train[np.random.randint(0, len(data_file_train), batch_size)]\n",
        "  y = np.concatenate([x[:, 1:], np.zeros([batch_size, 1])+VOCAB_SIZE-2], axis=-1)\n",
        "  return x, y\n",
        "\n",
        "def sampler_example_test(batch_size):\n",
        "  x = data_file_test[np.random.randint(0, len(data_file_test), batch_size)]\n",
        "  y = np.concatenate([x[:, 1:], np.zeros([batch_size, 1])+VOCAB_SIZE-2], axis=-1)\n",
        "  return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YpbTp_a5L1W"
      },
      "source": [
        "Функции обучения генератора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx23T6ef5MTA"
      },
      "source": [
        "# функция обучения генератора на основе MLE\n",
        "def train_generator_MLE(gen, gen_opt, real_samples_train, real_samples_test, epochs):\n",
        "    \"\"\"\n",
        "    Max Likelihood Pretraining for the generator\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        print('epoch %d : ' % (epoch + 1), end='')\n",
        "        sys.stdout.flush()\n",
        "        total_loss = 0\n",
        "\n",
        "        # обучение\n",
        "        for i in range(0, len(real_samples_train), BATCH_SIZE):\n",
        "            inp_train, target_train = helpers.prepare_generator_batch(real_samples_train[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                          gpu=CUDA)\n",
        "            gen_opt.zero_grad()\n",
        "            loss = gen.batchNLLLoss(inp_train, target_train)\n",
        "            loss.backward()\n",
        "            gen_opt.step()\n",
        "\n",
        "            total_loss += loss.data.item()\n",
        "\n",
        "            if (i / BATCH_SIZE) % ceil(\n",
        "                            ceil(len(real_samples_train) / float(BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
        "                print('.', end='')\n",
        "                sys.stdout.flush()\n",
        "\n",
        "        # each loss in a batch is loss per sample\n",
        "        total_loss = total_loss / ceil(len(real_samples_train) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "        print(' average_train_NLL = %.4f' % total_loss, end='')\n",
        "\n",
        "        # тестирование\n",
        "        test_loss = 0\n",
        "\n",
        "        for i in range(0, len(real_samples_test), BATCH_SIZE):\n",
        "            inp_test, target_test = helpers.prepare_generator_batch(real_samples_test[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                              gpu=CUDA)\n",
        "            loss = gen.batchNLLLoss(inp_test, target_test)\n",
        "            test_loss += loss.data.item()\n",
        "        test_loss = test_loss / ceil(len(real_samples_test) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "        print(' average_test_NLL = %.4f' % test_loss)\n",
        "\n",
        "def test_mle(gen, real_samples_train, real_samples_test):\n",
        "  '''\n",
        "  Тестирование генератора на обучающей и тестовой выборках.\n",
        "  '''\n",
        "  # тестирование на обучающей\n",
        "  test_loss = 0\n",
        "  for i in range(0, len(real_samples_train), BATCH_SIZE):\n",
        "      inp_test, target_test = helpers.prepare_generator_batch(real_samples_train[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                        gpu=CUDA)\n",
        "      loss = gen.batchNLLLoss(inp_test, target_test)\n",
        "      test_loss += loss.data.item()\n",
        "  test_loss = test_loss / ceil(len(real_samples_train) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "  print('average_train_NLL = %.4f' % test_loss, end='')\n",
        "\n",
        "  # тестирование на тестовой\n",
        "  test_loss = 0\n",
        "  for i in range(0, len(real_samples_test), BATCH_SIZE):\n",
        "      inp_test, target_test = helpers.prepare_generator_batch(real_samples_test[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                        gpu=CUDA)\n",
        "      loss = gen.batchNLLLoss(inp_test, target_test)\n",
        "      test_loss += loss.data.item()\n",
        "  test_loss = test_loss / ceil(len(real_samples_test) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "  print(' average_test_NLL = %.4f' % test_loss)\n",
        "\n",
        "# функция обучения генератора на основе обучения с подкреплением RL\n",
        "def train_generator_PG(gen, gen_opt, dis, num_batches):\n",
        "    \"\"\"\n",
        "    The generator is trained using policy gradients, using the reward from the discriminator.\n",
        "    Training is done for num_batches batches.\n",
        "    \"\"\"\n",
        "\n",
        "    for batch in range(num_batches):\n",
        "        s = gen.sample(BATCH_SIZE*4)        # 64 works best\n",
        "        inp, target = helpers.prepare_generator_batch(s, start_letter=START_LETTER, gpu=CUDA)\n",
        "        rewards = dis.batchClassify(target)\n",
        "\n",
        "        gen_opt.zero_grad()\n",
        "        pg_loss = gen.batchPGLoss(inp, target, rewards)\n",
        "        pg_loss.backward()\n",
        "        gen_opt.step()\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx5xFCA35pKw"
      },
      "source": [
        "Функция обучения дискриминатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSi-RHh45pk3"
      },
      "source": [
        "# функция обучения дискриминатора\n",
        "def train_discriminator(discriminator, dis_opt, real_data_samples, generator, d_steps, epochs):\n",
        "    \"\"\"\n",
        "    Training the discriminator on real_data_samples (positive) and generated samples from generator (negative).\n",
        "    Samples are drawn d_steps times, and the discriminator is trained for epochs epochs.\n",
        "    \"\"\"\n",
        "\n",
        "    # generating a small validation set before training\n",
        "    pos_val = real_data_samples[np.random.randint(0, len(real_data_samples), 500)] #sampler_example(250)\n",
        "    neg_val = generator.sample(500)\n",
        "    val_inp, val_target = helpers.prepare_discriminator_data(pos_val, neg_val, gpu=CUDA)\n",
        "\n",
        "    for d_step in range(d_steps):\n",
        "        s = helpers.batchwise_sample(generator, POS_NEG_SAMPLES, BATCH_SIZE)\n",
        "        dis_inp, dis_target = helpers.prepare_discriminator_data(real_data_samples, s, gpu=CUDA)\n",
        "        val_pred = discriminator.batchClassify(val_inp)\n",
        "        print('ДО ОБУЧЕНИЯ: val_acc = %.4f' % (\n",
        "            torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/1000.))\n",
        "        for epoch in range(epochs):\n",
        "            print('d-step %d epoch %d : ' % (d_step + 1, epoch + 1), end='')\n",
        "            sys.stdout.flush()\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "            for i in range(0, 2 * POS_NEG_SAMPLES, BATCH_SIZE):\n",
        "                inp, target = dis_inp[i:i + BATCH_SIZE], dis_target[i:i + BATCH_SIZE]\n",
        "                dis_opt.zero_grad()\n",
        "                out = discriminator.batchClassify(inp)\n",
        "                loss_fn = nn.BCELoss()\n",
        "                loss = loss_fn(out, target)\n",
        "                loss.backward()\n",
        "                dis_opt.step()\n",
        "\n",
        "                total_loss += loss.data.item()\n",
        "                total_acc += torch.sum((out>0.5)==(target>0.5)).data.item()\n",
        "\n",
        "                if (i / BATCH_SIZE) % ceil(ceil(2 * POS_NEG_SAMPLES / float(\n",
        "                        BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
        "                    print('.', end='')\n",
        "                    sys.stdout.flush()\n",
        "\n",
        "            total_loss /= ceil(2 * POS_NEG_SAMPLES / float(BATCH_SIZE))\n",
        "            total_acc /= float(2 * POS_NEG_SAMPLES)\n",
        "\n",
        "            val_pred = discriminator.batchClassify(val_inp)\n",
        "            print(' average_loss = %.4f, train_acc = %.4f, val_acc = %.4f' % (\n",
        "                total_loss, total_acc, torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/1000.))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBuFdlsb55XU"
      },
      "source": [
        "Функция оценки качества генерации текста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_D3lTI654PU"
      },
      "source": [
        "# оценка качества по BLEU метрике\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "import random\n",
        "from scipy import stats\n",
        "\n",
        "# функция оценки качества генерации текста по метрике BLEU\n",
        "def BLEU(reference_sample, test_sample, print_iteration=100, flag_print=True):\n",
        "  if flag_print:\n",
        "    print(\"--- --- ---\\nStart BLEU\")\n",
        "  pad = CLOSING_WORD\n",
        "  #################################################\n",
        "  reference = []\n",
        "  for line in reference_sample:\n",
        "    candidate = []\n",
        "    for i in line:\n",
        "      if i == pad:\n",
        "        break\n",
        "      candidate.append(i)\n",
        "\n",
        "    reference.append(candidate)\n",
        "  #################################################\n",
        "  hypothesis_list_leakgan = []\n",
        "  for line in test_sample:\n",
        "    while line[-1] == str(pad):\n",
        "      line.remove(str(pad))\n",
        "    hypothesis_list_leakgan.append(line)\n",
        "  #################################################\n",
        "  random.shuffle(hypothesis_list_leakgan)\n",
        "  #################################################\n",
        "\n",
        "  smoothing_function = SmoothingFunction().method1\n",
        "\n",
        "  mass_bleu = []\n",
        "  for ngram in range(2,6):\n",
        "      weight = tuple((1. / ngram for _ in range(ngram)))\n",
        "      bleu_leakgan = []\n",
        "      bleu_supervise = []\n",
        "      bleu_base2 = []\n",
        "      num = 0\n",
        "      for h in hypothesis_list_leakgan:\n",
        "          BLEUscore = nltk.translate.bleu_score.sentence_bleu(reference, h, weight, smoothing_function = smoothing_function)\n",
        "          num += 1\n",
        "          bleu_leakgan.append(BLEUscore)\n",
        "\n",
        "          if num%print_iteration == 0 and flag_print:\n",
        "            print(ngram, num, sum(bleu_leakgan)/len(bleu_leakgan))\n",
        "          \n",
        "      mass_bleu.append(1.0 * sum(bleu_leakgan) / len(bleu_leakgan))\n",
        "      if flag_print:\n",
        "        print('--- --- ---')\n",
        "        print(len(weight), '-gram BLEU score : ', 1.0 * sum(bleu_leakgan) / len(bleu_leakgan), \"\\n\")\n",
        "  return mass_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlNNlpWxIEM0"
      },
      "source": [
        "Функция сохранения моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idULo4Q_IC6z"
      },
      "source": [
        "# функция сохранения моделей (сериализация: моделей генератора и дискриминатора, параметров по умолчанию, обучающих данных)\n",
        "def save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer, name):\n",
        "  state = {\n",
        "      'default_parameters': {'VOCAB_SIZE': VOCAB_SIZE, 'MAX_SEQ_LEN': MAX_SEQ_LEN, 'GEN_EMBEDDING_DIM': GEN_EMBEDDING_DIM,\n",
        "                             'GEN_HIDDEN_DIM': GEN_HIDDEN_DIM, 'DIS_EMBEDDING_DIM': DIS_EMBEDDING_DIM, 'DIS_HIDDEN_DIM': DIS_HIDDEN_DIM},\n",
        "      'data_file_tensor_train': data_file_tensor_train,\n",
        "      'gen_state_dict': gen.state_dict(),\n",
        "      'dis_state_dict': dis.state_dict(),\n",
        "      'gen_optimizer': gen_optimizer.state_dict(),\n",
        "      'dis_optimizer': dis_optimizer.state_dict(),\n",
        "  }\n",
        "  torch.save(state, name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg9nWuCKHgZQ"
      },
      "source": [
        "Функция загрузки моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAlKsfNiHUnZ"
      },
      "source": [
        "# функция загрузки моделей (десериализация: моделей генератора и дискриминатора, параметров по умолчанию, обучающих данных)\n",
        "def load_models(name):\n",
        "  if CUDA:\n",
        "    device = torch.device('cuda')\n",
        "  else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "  print('state')\n",
        "  state = torch.load(name, map_location=device)\n",
        "\n",
        "  print('default_parameters')\n",
        "  VOCAB_SIZE = state['default_parameters']['VOCAB_SIZE']\n",
        "  MAX_SEQ_LEN = state['default_parameters']['MAX_SEQ_LEN']\n",
        "  GEN_EMBEDDING_DIM = state['default_parameters']['GEN_EMBEDDING_DIM']\n",
        "  GEN_HIDDEN_DIM = state['default_parameters']['GEN_HIDDEN_DIM']\n",
        "  DIS_EMBEDDING_DIM = state['default_parameters']['DIS_EMBEDDING_DIM']\n",
        "  DIS_HIDDEN_DIM = state['default_parameters']['DIS_HIDDEN_DIM']\n",
        "\n",
        "  print('data_file_tensor_train')\n",
        "  data_file_tensor_train = torch.tensor(state['data_file_tensor_train'])\n",
        "\n",
        "  print('Generator')\n",
        "  gen = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "  gen.load_state_dict(state['gen_state_dict'])\n",
        "  gen_optimizer = optim.Adam(gen.parameters(), lr=0.001)\n",
        "  gen_optimizer.load_state_dict(state['gen_optimizer'])\n",
        "\n",
        "  print('Discriminator')\n",
        "  dis = Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "  dis.load_state_dict(state['dis_state_dict'])\n",
        "  dis_optimizer = optim.Adagrad(dis.parameters())\n",
        "  dis_optimizer.load_state_dict(state['dis_optimizer'])\n",
        "\n",
        "  print('CUDA')\n",
        "  if CUDA:\n",
        "    data_file_tensor_train = data_file_tensor_train.cuda()\n",
        "    gen = gen.cuda()\n",
        "    dis = dis.cuda()\n",
        "  \n",
        "  return [data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "          VOCAB_SIZE, MAX_SEQ_LEN, GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vorPpC0M65Lv"
      },
      "source": [
        "Загрузка набора данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB8boRQzJ_sb"
      },
      "source": [
        "# загрузка словаря\n",
        "import pickle\n",
        "\n",
        "vocab_file = FILE_PATHS['vocab']\n",
        "word, vocab = pickle.load(open(vocab_file, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MmMIx2VQmal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7118b4-937c-4dc2-ad1c-6dd4e2f5562b"
      },
      "source": [
        "# загрузка обучающей выборки\n",
        "f = open(FILE_PATHS['train'], 'r')\n",
        "data_file_train = []\n",
        "for line in f:\n",
        "  line = line.replace('\\n', '')\n",
        "  line = line.split()\n",
        "  for i in range(len(line)):\n",
        "    line[i] = int(line[i])\n",
        "  data_file_train.append(line)\n",
        "data_file_train = np.array(data_file_train)[:, :MAX_SEQ_LEN]\n",
        "print(\"Примеров в обучающей выборке: \", len(data_file_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Примеров в обучающей выборке:  8704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHY_LhDP_o9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1313594-0ea8-4041-9a65-a04c33a0ec7f"
      },
      "source": [
        "# загрузка тестовой выборки\n",
        "f = open(FILE_PATHS['test'], 'r')\n",
        "data_file_test = []\n",
        "for line in f:\n",
        "  line = line.replace('\\n', '')\n",
        "  line = line.split()\n",
        "  for i in range(len(line)):\n",
        "    line[i] = int(line[i])\n",
        "  data_file_test.append(line)\n",
        "data_file_test = np.array(data_file_test)[:, :MAX_SEQ_LEN]\n",
        "print(\"Примеров в тестовой выборке: \", len(data_file_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Примеров в тестовой выборке:  968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc9jtz0qaQHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa162d9f-71f1-4201-e9ac-c1d13c5077d5"
      },
      "source": [
        "# примеры из обучающей выборки\n",
        "print(\"Примеры из обучающей выборки\")\n",
        "samples = sampler_example(50)[0]\n",
        "output_function = []\n",
        "for samp in samples:\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "\n",
        "for i, output in enumerate(output_function):\n",
        "  print(\"#\", i, \"\\tПример: \", output)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Примеры из обучающей выборки\n",
            "# 0 \tПример:  after learning of their son 's death on the battlefield , a grieving berlin couple embark on a quietly dangerous act of resistance against\n",
            "# 1 \tПример:  the pythons elevate the absurd to new heights and bring their sketches to german tv , working in phonetic german , at times with\n",
            "# 2 \tПример:  but after maddy is betrayed , she and cole reunite – to ruin prom .         \n",
            "# 3 \tПример:  when law student darby shaw theorizes about the assassinations of two supreme court justices , she is put in danger and turns to a\n",
            "# 4 \tПример:  fighting to survive , he reflects on his life and past romance .           \n",
            "# 5 \tПример:  two childhood best friends reunite as an unlikely crime-fighting superhero duo when one invents a formula that gives ordinary people superpowers .  \n",
            "# 6 \tПример:  a penniless country boy goes in search of his runaway sister in bogotá , where he falls for an aspiring singer , but gets\n",
            "# 7 \tПример:  kat and eva ’ s happy romance hits a rough patch when eva decides that she wants a child .    \n",
            "# 8 \tПример:  the elite real estate brokers at the oppenheim group sell the luxe life to affluent buyers in la .     \n",
            "# 9 \tПример:  the son of an astrologer faces opposition from his superstitious father regarding his scheme of launching a mango business .    \n",
            "# 10 \tПример:  a grieving mother takes a road trip with her friend to confront the man who , she believes , stole her late son 's\n",
            "# 11 \tПример:  a struggling couple ca n't believe their luck when they find a stash of money in the apartment of a neighbor who was recently\n",
            "# 12 \tПример:  eager for cash , rajesh joins his friend shankar 's blood-theft operation .           \n",
            "# 13 \tПример:  junior high students jason and kaylee take action when a greedy hollywood producer turns jason 's essay into a hit film without giving him\n",
            "# 14 \tПример:  this `` h2o '' sequel follows zac , a boy who accidentally turns into a merman and threatens the existence of three young mermaids\n",
            "# 15 \tПример:  a serial killer picks off a group of friends , one by one , as they make their way through a hell-themed amusement park\n",
            "# 16 \tПример:  french comic gad elmaleh regales a montreal crowd with tales of awkward mix-ups and baffling customs he 's encountered since moving to the u.s.\n",
            "# 17 \tПример:  while vacationing at a mountain cabin , a group of longtime friends uncovers an old scandal that could have deadly consequences .  \n",
            "# 18 \tПример:  former secretary of labor robert reich meets with americans from all walks of life as he chronicles a seismic shift in the nation 's\n",
            "# 19 \tПример:  from throwing parties to planning fashion shows , the hopscotch rabbit family is ready to leap into the daily adventures of their sweet town\n",
            "# 20 \tПример:  three friends born in poverty create their own capitalist dream as powerful gang members .         \n",
            "# 21 \tПример:  form , montage and mesmerizing kinetics propel this experimental meditation on the destructive power of the nuclear bomb , featuring music by the acid\n",
            "# 22 \tПример:  margaret thatcher , the first female prime minister of britain , navigates a career destined to change the rules of leadership and politics .\n",
            "# 23 \tПример:  personal desires guide the lives of a marriage-averse entrepreneur , a housewife coping with infidelity and a career woman who leaves her spouse .\n",
            "# 24 \tПример:  but their bond is shattered when the son learns of his father 's secret life .        \n",
            "# 25 \tПример:  a special operations officer vows to get revenge against the terrorist who killed his friend in a brutal attack .    \n",
            "# 26 \tПример:  the highs and lows of new parenting and adulting create drama and heartbreak as life moves on for the cast of `` 16 and\n",
            "# 27 \tПример:  rushing to pay off a loan shark , a young man breaks into a bungalow to steal the cash , unprepared for the dog\n",
            "# 28 \tПример:  burdened by troubles in life and love , a mother of three grown children searches for hope and healing on an impromptu trip to\n",
            "# 29 \tПример:  five schoolmates who share a blood type navigate the vagaries of friendship , love and university life .      \n",
            "# 30 \tПример:  this fact-based account delves into humankind 's efforts to gather signals from possible intelligent beings beyond the solar system .    \n",
            "# 31 \tПример:  as daily airstrikes pound civilian targets in syria , a group of indomitable first responders risk their lives to rescue victims from the rubble\n",
            "# 32 \tПример:  an oslo detective with a painful past returns to his native iceland to help a dedicated cop hunt a serial killer with a link\n",
            "# 33 \tПример:  when a team of researchers tries to find out what started a fire in a coal mine , they quickly discover that the disaster\n",
            "# 34 \tПример:  a deep dive into the work of renowned mexican journalist manuel buendía looks to unravel his murder and the ties between politics and drug\n",
            "# 35 \tПример:  part live-action and part animation , this visually inventive series offers striking portrayals of some of the unsung heroes of world war ii .\n",
            "# 36 \tПример:  the story of roberto baggio , one of the best soccer players of all time , including his career highs , triumphs over injuries\n",
            "# 37 \tПример:  but with every demon he battles , his humanity slips further away .           \n",
            "# 38 \tПример:  born in a stable in judea , brian grows up to join a group of anti-roman zealots , but his fate keeps getting confused\n",
            "# 39 \tПример:  in mid-1970s australia , two small-town teenage boys befriend an enigmatic middle-aged surfer , who urges them to see the thrill in facing their\n",
            "# 40 \tПример:  as a killing resembling a cold case resurfaces in a small town , the chase for the truth falls on two policemen who each\n",
            "# 41 \tПример:  in early 1990s malaysia , a tamilian boy faces pressure from his immigrant father to focus on school but is drawn to his uncles\n",
            "# 42 \tПример:  this dramatization depicts the life – and loves – of venezuelan gen. simón bolívar , who helped liberate several latin american countries from spain\n",
            "# 43 \tПример:  when her husband is accused of taking part in an attempted military coup , a pregnant woman 's life takes an emotional turn .\n",
            "# 44 \tПример:  iconic rocker john mellencamp lights up chicago in an electrifying live performance featuring old classics and new tracks .     \n",
            "# 45 \tПример:  after taking the blame for a patient death , an anesthesiologist battling psychiatric trauma fights to stay afloat in the corrupt hospital system .\n",
            "# 46 \tПример:  eleven-year-old amy starts to rebel against her conservative family ’ s traditions when she becomes fascinated with a free-spirited dance crew .  \n",
            "# 47 \tПример:  this irreverent documentary reveals how charming entertainer jan lewan bilked investors out of millions in a complicated investment scam .    \n",
            "# 48 \tПример:  a cop working undercover to trail a possible diamond thief gets caught in a tricky spot when she finds new clues — and new\n",
            "# 49 \tПример:  in justin 's dreams , he and his imaginary friends olive and squidgy travel around the world learning about nature and other cultures .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ2SVFc57G_h"
      },
      "source": [
        "Создание нейронных сетей генератора и дискриминатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LziOsVRduVtC"
      },
      "source": [
        "# объявление нейронных сетей генератора и дискриминатора, подготовка выборок данных для использования pytorch\n",
        "gen = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "dis = Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "\n",
        "if CUDA:\n",
        "  gen = gen.cuda()\n",
        "  dis = dis.cuda()\n",
        "  data_file_tensor_train = torch.tensor(data_file_train).cuda()\n",
        "  data_file_tensor_test = torch.tensor(data_file_test).cuda()\n",
        "else:\n",
        "  data_file_tensor_train = torch.tensor(data_file_train)\n",
        "  data_file_tensor_test = torch.tensor(data_file_test)\n",
        "\n",
        "gen_optimizer = optim.Adam(gen.parameters(), lr=0.001) #, lr=0.001\n",
        "dis_optimizer = optim.Adagrad(dis.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjtGu-Dh7Xn0"
      },
      "source": [
        "Обучение генератора на основе MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w7pqxEA3jhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a079996-48e8-4689-e4a1-9271da2f2597"
      },
      "source": [
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_train_NLL = 9.9228 average_test_NLL = 9.9233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_ZzVettuZHH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "outputId": "b9f7bfd3-0a6c-4ee2-bbf5-461b4b28e536"
      },
      "source": [
        "# обучение генератора на основе MLE / предобучение генератора\n",
        "print('Запуск обучения генератора на основе MLE...')\n",
        "gen_optimizer = optim.Adam(gen.parameters())#, lr=0.0002\n",
        "train_generator_MLE(gen, gen_optimizer, data_file_tensor_train, data_file_tensor_test, MLE_TRAIN_EPOCHS) # MLE_TRAIN_EPOCHS\n",
        "\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Запуск обучения генератора на основе MLE...\n",
            "epoch 1 : .......... average_train_NLL = 7.3663 average_test_NLL = 6.5351\n",
            "epoch 2 : .......... average_train_NLL = 6.3086 average_test_NLL = 6.3586\n",
            "epoch 3 : .......... average_train_NLL = 6.0647 average_test_NLL = 6.1910\n",
            "epoch 4 : .......... average_train_NLL = 5.8529 average_test_NLL = 6.0663\n",
            "epoch 5 : .......... average_train_NLL = 5.6757 average_test_NLL = 5.9727\n",
            "epoch 6 : .......... average_train_NLL = 5.5215 average_test_NLL = 5.8997\n",
            "epoch 7 : .......... average_train_NLL = 5.3839 average_test_NLL = 5.8430\n",
            "epoch 8 : .......... average_train_NLL = 5.2591 average_test_NLL = 5.7996\n",
            "epoch 9 : .......... average_train_NLL = 5.1441 average_test_NLL = 5.7657\n",
            "epoch 10 : .......... average_train_NLL = 5.0365 average_test_NLL = 5.7399\n",
            "epoch 11 : .......... average_train_NLL = 4.9347 average_test_NLL = 5.7202\n",
            "epoch 12 : .......... average_train_NLL = 4.8374 average_test_NLL = 5.7046\n",
            "epoch 13 : .......... average_train_NLL = 4.7436 average_test_NLL = 5.6926\n",
            "epoch 14 : .......... average_train_NLL = 4.6529 average_test_NLL = 5.6837\n",
            "epoch 15 : .......... average_train_NLL = 4.5646 average_test_NLL = 5.6773\n",
            "epoch 16 : .......... average_train_NLL = 4.4785 average_test_NLL = 5.6731\n",
            "epoch 17 : .......... average_train_NLL = 4.3951 average_test_NLL = 5.6699\n",
            "epoch 18 : .......... average_train_NLL = 4.3143 average_test_NLL = 5.6655\n",
            "epoch 19 : .......... average_train_NLL = 4.2371 average_test_NLL = 5.6646\n",
            "epoch 20 : .......... average_train_NLL = 4.1646 average_test_NLL = 5.6721\n",
            "epoch 21 : .......... average_train_NLL = 4.0938 average_test_NLL = 5.6813\n",
            "epoch 22 : .......... average_train_NLL = 4.0208 average_test_NLL = 5.6806\n",
            "epoch 23 : .......... average_train_NLL = 3.9457 average_test_NLL = 5.6857\n",
            "epoch 24 : .......... average_train_NLL = 3.8726 average_test_NLL = 5.6952\n",
            "epoch 25 : .......... average_train_NLL = 3.8028 average_test_NLL = 5.7052\n",
            "epoch 26 : .......... average_train_NLL = 3.7368 average_test_NLL = 5.7183\n",
            "epoch 27 : .......... average_train_NLL = 3.6741 average_test_NLL = 5.7352\n",
            "epoch 28 : .......... average_train_NLL = 3.6144 average_test_NLL = 5.7590\n",
            "epoch 29 : .......... average_train_NLL = 3.5556 average_test_NLL = 5.7800\n",
            "epoch 30 : .......... average_train_NLL = 3.4970 average_test_NLL = 5.7914\n",
            "average_train_NLL = 3.4587 average_test_NLL = 5.7914\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-99b77aae77df>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_mle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file_tensor_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file_tensor_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# сохранение результата обучения\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n\u001b[0m\u001b[1;32m      9\u001b[0m             FILE_PATHS['saved_models'] + r'/' + r'seqgan_mle.pytorch')\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# epoch 1 : .......... average_train_NLL = 1.8447 average_test_NLL = 1.9937\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-6204e9355630>\u001b[0m in \u001b[0;36msave_models\u001b[0;34m(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer, name)\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;34m'dis_optimizer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdis_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   }\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_writer_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Parent directory saved_models/netflix_titles does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сохранение результата обучения\n",
        "save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "            FILE_PATHS['saved_models'] + r'/' + r'seqgan_mle.pytorch')"
      ],
      "metadata": {
        "id": "CUd1PqSehCOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vE1qrmlgJNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493a3965-ca94-42b3-a537-7c37fe12fff7"
      },
      "source": [
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_train_NLL = 3.4587 average_test_NLL = 5.7914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2AFMeIuIg6R"
      },
      "source": [
        "Генерация примеров текстов на основе MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGaETrFgIfzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835047c3-e18b-4eb0-9292-812e2a299c63"
      },
      "source": [
        "# примеры сгенерированных текстов\n",
        "print(\"Примеры генерируемых текстов на основе MLE\")\n",
        "degree = 1\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tПример: \", line, ' '*(100-len(line)), '\\tОценка: ', bleu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Примеры генерируемых текстов на основе MLE\n",
            "Degree: 1\n",
            "# 0 \tПример:  a district cow as a newly account to the first business terrain , an natural adventure uses the time can their secret kimchee differences  \tОценка:  [0.48900964692182575, 0.10281837227019264, 0.047697785860210014, 0.03038033625841874]\n",
            "# 1 \tПример:  the street final performance at stake at his life choices .                                           \tОценка:  [0.8846517369293828, 0.7926534264491066, 0.7451496818790302, 0.7135510776575065]\n",
            "# 2 \tПример:  this documentary explores the true life and producers of skull castle in this entertaining supply italy series .        \tОценка:  [0.6689273264831853, 0.5459359922380247, 0.4643434078111817, 0.39235340559600385]\n",
            "# 3 \tПример:  this hindi outback album of musicians characters to the classic moments of the rest of teachers with his mother 's body , a thankless  \tОценка:  [0.6313087395543334, 0.3787861220823229, 0.1268354694168578, 0.06643341491719774]\n",
            "# 4 \tПример:  an actor is forced to the case , romance with his pretty roots , aka finds more than real threatening jealous and find themselves  \tОценка:  [0.6915640748081247, 0.2790920009998241, 0.1008685361966555, 0.05530935266797243]\n",
            "# 5 \tПример:  eager to their woodland job , ambitious hosted veteran igor who would get the foundation of the paradise ring , credit for human beings  \tОценка:  [0.46625240412015684, 0.09960317042892669, 0.04657469807170698, 0.02980670980951787]\n",
            "# 6 \tПример:  a grieving hotel sketch the victim to watch 's prostitution , who urges his niece will .              \tОценка:  [0.5516772843673705, 0.43621399128699967, 0.37494051432044967, 0.33065561022448725]\n",
            "# 7 \tПример:  when gooey does framed for her stepmother ’ s infant show , utopian may discover the ages of traditional healers .     \tОценка:  [0.4777665429529547, 0.2747975949405749, 0.17729842264695017, 0.08684761539367104]\n",
            "# 8 \tПример:  between the nazis who manages her family to attend a rich village 's law , schooling ends with an unconventional enemy in the gang  \tОценка:  [0.5281907867867224, 0.233195225379592, 0.08815255754657725, 0.04965716648147243]\n",
            "# 9 \tПример:  ship live-action schoolboys out to her passion date , a dangerous water and family work try to where suspects and earth , are tasked  \tОценка:  [0.6915640748081247, 0.12954303153914298, 0.05672254631483793, 0.034897842284302386]\n",
            "# 10 \tПример:  in a lawless man who experience his help from one of the town 's been untouched for fun and cannibal race , comic dumpty  \tОценка:  [0.5247497678328021, 0.23218132028972122, 0.08786494341132738, 0.049527511535197015]\n",
            "# 11 \tПример:  monkey and family take a robotic writer on returning to let the dreams , this short career combat and richly paired the heart of  \tОценка:  [0.42562826537937426, 0.09373017196439742, 0.04449945957170705, 0.02873940616731871]\n",
            "# 12 \tПример:  this remake of the rise and family run from the magical lost royal cadets and music amos cure-all .       \tОценка:  [0.6756639246921762, 0.4993403686272635, 0.39242591746953154, 0.29854248663311195]\n",
            "# 13 \tПример:  a college student falls under his funky build a series that they may not park beyond while conducting stalked and wake on an experimental  \tОценка:  [0.5281907867867224, 0.10823963541737297, 0.049571826029660766, 0.031331553897560704]\n",
            "# 14 \tПример:  the corrupt crew of dramas joins a successful writer and a young woman winner of her parents leads a work in demonic apartment with  \tОценка:  [0.6770032003863301, 0.2751606040745523, 0.09980099403873667, 0.0548405617099861]\n",
            "# 15 \tПример:  in this comedy-drama , with the tensions drama to seek their magical kingpin journeys perspective in the beginnings and industry horror trees .   \tОценка:  [0.51604684654214, 0.22960703587480308, 0.08713328153838423, 0.04919729867236533]\n",
            "# 16 \tПример:  two jinns siblings invite stories – and the company and must fall in the strange winter best backyard smokers mysteries .     \tОценка:  [0.51604684654214, 0.3311506488299924, 0.2039221418719747, 0.09713271053554523]\n",
            "# 17 \tПример:  when a theater assembles suspects sami , teaming up with established comes runner , a rookie loner brings him jail challenges a brave when  \tОценка:  [0.42562826537937426, 0.20193553398275174, 0.07913247271422609, 0.04554888918995836]\n",
            "# 18 \tПример:  struggling at a to reach a complicated , minister singer is forced to buy a hostage game in modern street .     \tОценка:  [0.5773502691896258, 0.35688292775180414, 0.21569471602226037, 0.10159342591157826]\n",
            "# 19 \tПример:  with the young violent leader of a wealthy professor ways to court , piety and – without her dream sister sends his reclusive-banker hurricane  \tОценка:  [0.51604684654214, 0.22960703587480308, 0.08713328153838423, 0.04919729867236533]\n",
            "# 20 \tПример:  after his brother , a detective mario conde drifting into a tour scandal .                            \tОценка:  [0.7801894976054939, 0.6516171503560686, 0.5697863655544793, 0.5168722914580963]\n",
            "# 21 \tПример:  an app alerts bomb turns to stay out of his bad guys 's skills in their 60s in prison .               \tОценка:  [0.5383819020581655, 0.37492068785758975, 0.26616885054222045, 0.19051088045447015]\n",
            "# 22 \tПример:  when a cruise benny to pinpoint the hidden dynasty , who has compete to fulfill the perfect he lives during their past from the  \tОценка:  [0.51604684654214, 0.2892867377026317, 0.10361951835898177, 0.05651285605524387]\n",
            "# 23 \tПример:  this documentary examines the true-crime episodes leading to rio 's murder cases in this intimate spaghetti into action comedy .      \tОценка:  [0.6426845869171514, 0.48295660834948184, 0.3827289014610808, 0.2926260648528894]\n",
            "# 24 \tПример:  four teenage young recalls boyfriend to know down and family .                                        \tОценка:  [0.7731921410338582, 0.6883000627148177, 0.64287524738418, 0.6113576689555066]\n",
            "# 25 \tПример:  these stand-up comic gina yashere brings his rise to rival when lovable solutions to keep hidden one joins forces .      \tОценка:  [0.5516772843673705, 0.34622327432611516, 0.250737833894674, 0.18162260340771427]\n",
            "# 26 \tПример:  while overnighting from the harsh realities , a hedonistic chef becomes possessed with his attacker to home just a way : and studio they  \tОценка:  [0.4777665429529547, 0.10123629955117001, 0.04714627368490469, 0.030098988375222294]\n",
            "# 27 \tПример:  a black hole ' lives of murders — and the impressionable new friend ( famous maury created .          \tОценка:  [0.6915640748081247, 0.5338837915749062, 0.4362874590298468, 0.3732709419770685]\n",
            "# 28 \tПример:  writer and archival footage , his edgy crew ma bohannon is forced to marry his forest , a group of hijackers get caught up  \tОценка:  [0.586688076025689, 0.3970244729630614, 0.2778533476615993, 0.12440748421169556]\n",
            "# 29 \tПример:  defeated is uprooted to destroy their bodies in time .                                                \tОценка:  [0.8469895538599198, 0.7699936689929985, 0.7146704964214272, 0.6781991182044285]\n",
            "# 30 \tПример:  after a remote tale of an the job , a pretty village , a young man returns to becoming a vengeful raid from a  \tОценка:  [0.719802710490163, 0.41340447784296236, 0.24083885767888158, 0.11096224830448143]\n",
            "# 31 \tПример:  an filmmaker hunts for him for justice after his brother wife is , a man is inspired by a crazed killer who can feed  \tОценка:  [0.6621221919717306, 0.3910133818364098, 0.12989394049125555, 0.0677119177821849]\n",
            "# 32 \tПример:  a palestinian 's tough woman in his domineering interest has a christmas connection to rescue her murder and murderous extensive life , fighting first  \tОценка:  [0.5989120571285179, 0.2535719111557542, 0.0938687499151236, 0.05221686911163813]\n",
            "# 33 \tПример:  years after her boyfriend , a recruited for a young couple is sucked into letting his family and reveals a photographic moves to come  \tОценка:  [0.659380473395787, 0.2703646004809834, 0.09849349468888721, 0.054265028889194544]\n",
            "# 34 \tПример:  science 's best friends , kirk kidnap lead to steal his dead records for a traveling tries to help from meeting around the world  \tОценка:  [0.6770032003863301, 0.2751606040745523, 0.09980099403873667, 0.0548405617099861]\n",
            "# 35 \tПример:  three independence , joey and career recorded in personality and looks on sports and becomes embroiled in this , ungrateful ensemble satire over her  \tОценка:  [0.4544466295731929, 0.09791465490261936, 0.04598126864749705, 0.02950249602200936]\n",
            "# 36 \tПример:  when his loss party tries to avoid his size , identity through the government she becomes mystical discusses a pretty car with amnesia for  \tОценка:  [0.51604684654214, 0.22960703587480308, 0.08713328153838423, 0.04919729867236533]\n",
            "# 37 \tПример:  stoner : black morgan , then does she 's members for a amid love triangle of origin , dating sets out to destroy a  \tОценка:  [0.48900964692182575, 0.22151546799151528, 0.08481999049965716, 0.04814958812064739]\n",
            "# 38 \tПример:  after many years themselves , a thief writer vows to get him for his run-in and glides into christmas all too credit , assassins  \tОценка:  [0.4361391879943235, 0.2052465410515309, 0.08010360497032464, 0.04599553238160709]\n",
            "# 39 \tПример:  when it gets pulled into a sharecropper .                                                             \tОценка:  [0.8897565210026093, 0.831916785353757, 0.7871130275822675, 0.7575518301491964]\n",
            "# 40 \tПример:  away and must arrange their relationship ' place !                                                    \tОценка:  [0.7985494095046904, 0.7403486921630513, 0.7079592321389286, 0.6849152714460243]\n",
            "# 41 \tПример:  teams with autobiographical confections that goes her to los angeles in recovery .                    \tОценка:  [0.7905694150420949, 0.6786044041487267, 0.6049483675122199, 0.5569120893014395]\n",
            "# 42 \tПример:  this documentary profiles ayrton late-night tv lady and food cosmic around his prized .               \tОценка:  [0.659380473395787, 0.5623810317863845, 0.5102002548573253, 0.473157954725232]\n",
            "# 43 \tПример:  three allen rachel struggles to rob the battle against life before if he brings him face-to-face with targeted , – but his destiny for  \tОценка:  [0.6255432421712244, 0.2610341517375316, 0.0959330328254962, 0.053133514170325934]\n",
            "# 44 \tПример:  a man of two staying in feudal the bond with three brothers in 1881 , who was n't want autumn to division their lives  \tОценка:  [0.5710402407201608, 0.24564254155341458, 0.0916585247474253, 0.05123093607434564]\n",
            "# 45 \tПример:  the lover is imprisoned of pregnant and treasure 20 years later , who has a first , ungrateful robot self-help affects completely their lives  \tОценка:  [0.5036101551853349, 0.28462000651909863, 0.10236329204211274, 0.05596408357472806]\n",
            "# 46 \tПример:  a wealthy general begrudgingly is healed cop is drawn to go legit with emily might know their country and a dead-end series finds himself  \tОценка:  [0.4423258684646914, 0.09616580372219406, 0.045363930410469634, 0.029185191097358284]\n",
            "# 47 \tПример:  bore , a peasant from toronto of money , blades and except do whatever the fake of fame — inside the real muccioli set  \tОценка:  [0.4148511169990534, 0.09214121801881725, 0.04393247170566369, 0.028446085513788744]\n",
            "# 48 \tПример:  when a young prostitute forms an insurance adjuster for a every surprise artist in this stream-of-consciousness series that dissects them henry alternate scenes from  \tОценка:  [0.46625240412015684, 0.2145885256092375, 0.08282282660969602, 0.04724045146676876]\n",
            "# 49 \tПример:  separated by new evil to make a exacts , a member of a kindly hustler by the life of meditation , a meek police  \tОценка:  [0.6468989572333266, 0.4564642209568224, 0.259418075232376, 0.11775902116073575]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lZnWDHB7xsN"
      },
      "source": [
        "Оценка качества генерации текста после обучения с помощью MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R2_zZKV7yPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa4b3f2-5d7b-48cd-d5ab-65b46f6fa6b6"
      },
      "source": [
        "print(\"Оценка качества генерации текста на основе BLEU, после обучения с помощью MLE\")\n",
        "# проверка качества обучения\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оценка качества генерации текста на основе BLEU, после обучения с помощью MLE\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.5948866545792448\n",
            "2 200 0.6054552359457742\n",
            "2 300 0.6016202455435079\n",
            "2 400 0.6005756808019966\n",
            "2 500 0.604328182451673\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.604328182451673 \n",
            "\n",
            "3 100 0.33878084409882786\n",
            "3 200 0.35751802465740956\n",
            "3 300 0.3604365532516006\n",
            "3 400 0.3588395654152625\n",
            "3 500 0.3626909506096581\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.3626909506096581 \n",
            "\n",
            "4 100 0.23614141588392815\n",
            "4 200 0.2538859337269141\n",
            "4 300 0.25550202397863003\n",
            "4 400 0.25226020522824966\n",
            "4 500 0.2537040848961532\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.2537040848961532 \n",
            "\n",
            "5 100 0.19438796915345255\n",
            "5 200 0.20851230711370494\n",
            "5 300 0.21056530155429862\n",
            "5 400 0.2073277189558224\n",
            "5 500 0.20767160383787964\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.20767160383787964 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.604328182451673,\n",
              " 0.3626909506096581,\n",
              " 0.2537040848961532,\n",
              " 0.20767160383787964]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdrWQfpV7bie"
      },
      "source": [
        "Предварительное обучение дискриминатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVypqCS4ucWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24817723-18a3-4379-ee11-87572854f4ff"
      },
      "source": [
        "# предобучение дискриминатора\n",
        "print('Запуск обучения дискриминатора...')\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters()) # , lr=0.0001\n",
        "# dis_optimizer = optim.Adam(gen.parameters(), lr=0.001, weight_decay=1e-5)#0.001\n",
        "# dis_optimizer = optim.Adadelta(gen.parameters())\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters())#, lr=0.0001)#, weight_decay=1e-5)\n",
        "#, weight_decay=1e-5) # регуляризация\n",
        "train_discriminator(dis, dis_optimizer, data_file_tensor_train, gen, DIS_TRAIN_ITERATIONS, DIS_TRAIN_EPOCHS)#25, 1 | (15, 3), (25, 1)\n",
        "\n",
        "# сохранение результата обучения\n",
        "save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "            FILE_PATHS['saved_models'] + r'/' + r'seqgan_pretraining_dis.pytorch')\n",
        "\n",
        "# ДО ОБУЧЕНИЯ: val_acc = 0.5230\n",
        "# d-step 50 epoch 1 : .......... average_loss = 0.2859, train_acc = 0.9136, val_acc = 0.5240"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Запуск обучения дискриминатора...\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.4980\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.3812, train_acc = 0.8870, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.3481, train_acc = 0.8900, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.3411, train_acc = 0.8905, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.3116, train_acc = 0.9020, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.3053, train_acc = 0.9020, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 6 epoch 1 : .......... average_loss = 0.3233, train_acc = 0.8970, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 7 epoch 1 : .......... average_loss = 0.3377, train_acc = 0.8885, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 8 epoch 1 : .......... average_loss = 0.3399, train_acc = 0.8885, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 9 epoch 1 : .......... average_loss = 0.3018, train_acc = 0.9050, val_acc = 0.5010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5010\n",
            "d-step 10 epoch 1 : .......... average_loss = 0.3132, train_acc = 0.8990, val_acc = 0.5010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5010\n",
            "d-step 11 epoch 1 : .......... average_loss = 0.2969, train_acc = 0.9035, val_acc = 0.5010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5010\n",
            "d-step 12 epoch 1 : .......... average_loss = 0.3267, train_acc = 0.8890, val_acc = 0.5020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5020\n",
            "d-step 13 epoch 1 : .......... average_loss = 0.2979, train_acc = 0.8980, val_acc = 0.5010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5010\n",
            "d-step 14 epoch 1 : .......... average_loss = 0.3188, train_acc = 0.8945, val_acc = 0.5030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5030\n",
            "d-step 15 epoch 1 : .......... average_loss = 0.3092, train_acc = 0.8965, val_acc = 0.5020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5020\n",
            "d-step 16 epoch 1 : .......... average_loss = 0.2903, train_acc = 0.9020, val_acc = 0.5020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5020\n",
            "d-step 17 epoch 1 : .......... average_loss = 0.2940, train_acc = 0.9035, val_acc = 0.5010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5010\n",
            "d-step 18 epoch 1 : .......... average_loss = 0.3219, train_acc = 0.8920, val_acc = 0.5030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5020\n",
            "d-step 19 epoch 1 : .......... average_loss = 0.3218, train_acc = 0.8895, val_acc = 0.5020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5020\n",
            "d-step 20 epoch 1 : .......... average_loss = 0.2939, train_acc = 0.9040, val_acc = 0.5030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5020\n",
            "d-step 21 epoch 1 : .......... average_loss = 0.2875, train_acc = 0.9030, val_acc = 0.5020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5020\n",
            "d-step 22 epoch 1 : .......... average_loss = 0.2931, train_acc = 0.8980, val_acc = 0.5050\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5050\n",
            "d-step 23 epoch 1 : .......... average_loss = 0.3161, train_acc = 0.8895, val_acc = 0.5020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5020\n",
            "d-step 24 epoch 1 : .......... average_loss = 0.2912, train_acc = 0.8985, val_acc = 0.5070\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5060\n",
            "d-step 25 epoch 1 : .......... average_loss = 0.3029, train_acc = 0.8890, val_acc = 0.5070\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5070\n",
            "d-step 26 epoch 1 : .......... average_loss = 0.3014, train_acc = 0.8980, val_acc = 0.5070\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5050\n",
            "d-step 27 epoch 1 : .......... average_loss = 0.2851, train_acc = 0.9030, val_acc = 0.5300\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5290\n",
            "d-step 28 epoch 1 : .......... average_loss = 0.3066, train_acc = 0.8910, val_acc = 0.5290\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5270\n",
            "d-step 29 epoch 1 : .......... average_loss = 0.3083, train_acc = 0.8940, val_acc = 0.5270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5330\n",
            "d-step 30 epoch 1 : .......... average_loss = 0.2749, train_acc = 0.9140, val_acc = 0.5250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5250\n",
            "d-step 31 epoch 1 : .......... average_loss = 0.2907, train_acc = 0.8995, val_acc = 0.5450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5390\n",
            "d-step 32 epoch 1 : .......... average_loss = 0.2914, train_acc = 0.9070, val_acc = 0.5390\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5390\n",
            "d-step 33 epoch 1 : .......... average_loss = 0.2766, train_acc = 0.9005, val_acc = 0.5540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5600\n",
            "d-step 34 epoch 1 : .......... average_loss = 0.2934, train_acc = 0.9030, val_acc = 0.5440\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5490\n",
            "d-step 35 epoch 1 : .......... average_loss = 0.2734, train_acc = 0.9075, val_acc = 0.5570\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5550\n",
            "d-step 36 epoch 1 : .......... average_loss = 0.2789, train_acc = 0.9045, val_acc = 0.5530\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5520\n",
            "d-step 37 epoch 1 : .......... average_loss = 0.2677, train_acc = 0.9125, val_acc = 0.5520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5510\n",
            "d-step 38 epoch 1 : .......... average_loss = 0.2782, train_acc = 0.9085, val_acc = 0.5650\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5670\n",
            "d-step 39 epoch 1 : .......... average_loss = 0.2749, train_acc = 0.9080, val_acc = 0.5680\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5630\n",
            "d-step 40 epoch 1 : .......... average_loss = 0.2991, train_acc = 0.8940, val_acc = 0.5850\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5860\n",
            "d-step 41 epoch 1 : .......... average_loss = 0.2862, train_acc = 0.9045, val_acc = 0.5590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5640\n",
            "d-step 42 epoch 1 : .......... average_loss = 0.2664, train_acc = 0.9115, val_acc = 0.5830\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5850\n",
            "d-step 43 epoch 1 : .......... average_loss = 0.2735, train_acc = 0.9095, val_acc = 0.5940\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5910\n",
            "d-step 44 epoch 1 : .......... average_loss = 0.2453, train_acc = 0.9235, val_acc = 0.6240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6240\n",
            "d-step 45 epoch 1 : .......... average_loss = 0.2710, train_acc = 0.9095, val_acc = 0.5910\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6010\n",
            "d-step 46 epoch 1 : .......... average_loss = 0.2467, train_acc = 0.9195, val_acc = 0.5960\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5910\n",
            "d-step 47 epoch 1 : .......... average_loss = 0.2541, train_acc = 0.9180, val_acc = 0.6020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6090\n",
            "d-step 48 epoch 1 : .......... average_loss = 0.2571, train_acc = 0.9115, val_acc = 0.5920\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5990\n",
            "d-step 49 epoch 1 : .......... average_loss = 0.2455, train_acc = 0.9200, val_acc = 0.5930\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5930\n",
            "d-step 50 epoch 1 : .......... average_loss = 0.2771, train_acc = 0.9095, val_acc = 0.6210\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6190\n",
            "d-step 51 epoch 1 : .......... average_loss = 0.2702, train_acc = 0.9070, val_acc = 0.6300\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6360\n",
            "d-step 52 epoch 1 : .......... average_loss = 0.2624, train_acc = 0.9155, val_acc = 0.6240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6270\n",
            "d-step 53 epoch 1 : .......... average_loss = 0.2490, train_acc = 0.9225, val_acc = 0.6390\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6390\n",
            "d-step 54 epoch 1 : .......... average_loss = 0.2560, train_acc = 0.9180, val_acc = 0.6420\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6360\n",
            "d-step 55 epoch 1 : .......... average_loss = 0.2395, train_acc = 0.9180, val_acc = 0.6710\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6750\n",
            "d-step 56 epoch 1 : .......... average_loss = 0.2483, train_acc = 0.9165, val_acc = 0.6490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6500\n",
            "d-step 57 epoch 1 : .......... average_loss = 0.2431, train_acc = 0.9230, val_acc = 0.6550\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6530\n",
            "d-step 58 epoch 1 : .......... average_loss = 0.2662, train_acc = 0.9140, val_acc = 0.6420\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6350\n",
            "d-step 59 epoch 1 : .......... average_loss = 0.2610, train_acc = 0.9175, val_acc = 0.6430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6460\n",
            "d-step 60 epoch 1 : .......... average_loss = 0.2466, train_acc = 0.9215, val_acc = 0.6610\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6650\n",
            "d-step 61 epoch 1 : .......... average_loss = 0.2386, train_acc = 0.9245, val_acc = 0.6810\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6880\n",
            "d-step 62 epoch 1 : .......... average_loss = 0.2420, train_acc = 0.9220, val_acc = 0.6810\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6810\n",
            "d-step 63 epoch 1 : .......... average_loss = 0.2385, train_acc = 0.9195, val_acc = 0.6660\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6590\n",
            "d-step 64 epoch 1 : .......... average_loss = 0.2191, train_acc = 0.9375, val_acc = 0.6680\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6730\n",
            "d-step 65 epoch 1 : .......... average_loss = 0.2279, train_acc = 0.9285, val_acc = 0.7030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7000\n",
            "d-step 66 epoch 1 : .......... average_loss = 0.2084, train_acc = 0.9400, val_acc = 0.6720\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6770\n",
            "d-step 67 epoch 1 : .......... average_loss = 0.2173, train_acc = 0.9345, val_acc = 0.6870\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6920\n",
            "d-step 68 epoch 1 : .......... average_loss = 0.2161, train_acc = 0.9340, val_acc = 0.6770\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6800\n",
            "d-step 69 epoch 1 : .......... average_loss = 0.2224, train_acc = 0.9330, val_acc = 0.7020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6970\n",
            "d-step 70 epoch 1 : .......... average_loss = 0.2061, train_acc = 0.9395, val_acc = 0.6890\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6900\n",
            "d-step 71 epoch 1 : .......... average_loss = 0.2168, train_acc = 0.9315, val_acc = 0.7020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6980\n",
            "d-step 72 epoch 1 : .......... average_loss = 0.2123, train_acc = 0.9330, val_acc = 0.7030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7050\n",
            "d-step 73 epoch 1 : .......... average_loss = 0.1881, train_acc = 0.9425, val_acc = 0.7240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7220\n",
            "d-step 74 epoch 1 : .......... average_loss = 0.1887, train_acc = 0.9460, val_acc = 0.7010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7000\n",
            "d-step 75 epoch 1 : .......... average_loss = 0.2011, train_acc = 0.9430, val_acc = 0.7180\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7200\n",
            "d-step 76 epoch 1 : .......... average_loss = 0.1976, train_acc = 0.9410, val_acc = 0.7460\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7390\n",
            "d-step 77 epoch 1 : .......... average_loss = 0.2036, train_acc = 0.9385, val_acc = 0.7200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7200\n",
            "d-step 78 epoch 1 : .......... average_loss = 0.1757, train_acc = 0.9465, val_acc = 0.7050\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7120\n",
            "d-step 79 epoch 1 : .......... average_loss = 0.2089, train_acc = 0.9340, val_acc = 0.7210\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7190\n",
            "d-step 80 epoch 1 : .......... average_loss = 0.1932, train_acc = 0.9410, val_acc = 0.7090\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7130\n",
            "d-step 81 epoch 1 : .......... average_loss = 0.2117, train_acc = 0.9345, val_acc = 0.7520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7510\n",
            "d-step 82 epoch 1 : .......... average_loss = 0.1956, train_acc = 0.9400, val_acc = 0.7370\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7410\n",
            "d-step 83 epoch 1 : .......... average_loss = 0.1852, train_acc = 0.9460, val_acc = 0.7250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7280\n",
            "d-step 84 epoch 1 : .......... average_loss = 0.1835, train_acc = 0.9460, val_acc = 0.7230\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7200\n",
            "d-step 85 epoch 1 : .......... average_loss = 0.1791, train_acc = 0.9500, val_acc = 0.7350\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7250\n",
            "d-step 86 epoch 1 : .......... average_loss = 0.1987, train_acc = 0.9360, val_acc = 0.7520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7510\n",
            "d-step 87 epoch 1 : .......... average_loss = 0.1825, train_acc = 0.9520, val_acc = 0.7270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7270\n",
            "d-step 88 epoch 1 : .......... average_loss = 0.1645, train_acc = 0.9495, val_acc = 0.7420\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7430\n",
            "d-step 89 epoch 1 : .......... average_loss = 0.1752, train_acc = 0.9480, val_acc = 0.7410\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7390\n",
            "d-step 90 epoch 1 : .......... average_loss = 0.1860, train_acc = 0.9430, val_acc = 0.7240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7160\n",
            "d-step 91 epoch 1 : .......... average_loss = 0.1939, train_acc = 0.9475, val_acc = 0.7380\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7420\n",
            "d-step 92 epoch 1 : .......... average_loss = 0.1715, train_acc = 0.9480, val_acc = 0.7600\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7590\n",
            "d-step 93 epoch 1 : .......... average_loss = 0.1587, train_acc = 0.9505, val_acc = 0.7660\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7750\n",
            "d-step 94 epoch 1 : .......... average_loss = 0.1714, train_acc = 0.9455, val_acc = 0.7510\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7550\n",
            "d-step 95 epoch 1 : .......... average_loss = 0.1849, train_acc = 0.9475, val_acc = 0.7660\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7660\n",
            "d-step 96 epoch 1 : .......... average_loss = 0.1716, train_acc = 0.9475, val_acc = 0.7970\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7900\n",
            "d-step 97 epoch 1 : .......... average_loss = 0.1714, train_acc = 0.9490, val_acc = 0.7560\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7600\n",
            "d-step 98 epoch 1 : .......... average_loss = 0.1855, train_acc = 0.9510, val_acc = 0.7770\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7780\n",
            "d-step 99 epoch 1 : .......... average_loss = 0.1654, train_acc = 0.9540, val_acc = 0.7750\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7800\n",
            "d-step 100 epoch 1 : .......... average_loss = 0.1587, train_acc = 0.9585, val_acc = 0.7750\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7730\n",
            "d-step 101 epoch 1 : .......... average_loss = 0.1741, train_acc = 0.9530, val_acc = 0.7450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7450\n",
            "d-step 102 epoch 1 : .......... average_loss = 0.1670, train_acc = 0.9540, val_acc = 0.7930\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7900\n",
            "d-step 103 epoch 1 : .......... average_loss = 0.1447, train_acc = 0.9585, val_acc = 0.7790\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7710\n",
            "d-step 104 epoch 1 : .......... average_loss = 0.1341, train_acc = 0.9630, val_acc = 0.7820\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7770\n",
            "d-step 105 epoch 1 : .......... average_loss = 0.1788, train_acc = 0.9460, val_acc = 0.7910\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7870\n",
            "d-step 106 epoch 1 : .......... average_loss = 0.1863, train_acc = 0.9480, val_acc = 0.7810\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7850\n",
            "d-step 107 epoch 1 : .......... average_loss = 0.1513, train_acc = 0.9565, val_acc = 0.7910\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7970\n",
            "d-step 108 epoch 1 : .......... average_loss = 0.1833, train_acc = 0.9495, val_acc = 0.7980\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7970\n",
            "d-step 109 epoch 1 : .......... average_loss = 0.1615, train_acc = 0.9515, val_acc = 0.7840\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7800\n",
            "d-step 110 epoch 1 : .......... average_loss = 0.1693, train_acc = 0.9470, val_acc = 0.7980\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7900\n",
            "d-step 111 epoch 1 : .......... average_loss = 0.1611, train_acc = 0.9520, val_acc = 0.7910\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7840\n",
            "d-step 112 epoch 1 : .......... average_loss = 0.1696, train_acc = 0.9490, val_acc = 0.8190\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8130\n",
            "d-step 113 epoch 1 : .......... average_loss = 0.1407, train_acc = 0.9610, val_acc = 0.8030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7950\n",
            "d-step 114 epoch 1 : .......... average_loss = 0.1444, train_acc = 0.9605, val_acc = 0.8040\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8060\n",
            "d-step 115 epoch 1 : .......... average_loss = 0.1556, train_acc = 0.9570, val_acc = 0.7930\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7900\n",
            "d-step 116 epoch 1 : .......... average_loss = 0.1465, train_acc = 0.9630, val_acc = 0.8000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8050\n",
            "d-step 117 epoch 1 : .......... average_loss = 0.1410, train_acc = 0.9620, val_acc = 0.7980\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8000\n",
            "d-step 118 epoch 1 : .......... average_loss = 0.1372, train_acc = 0.9610, val_acc = 0.8050\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8080\n",
            "d-step 119 epoch 1 : .......... average_loss = 0.1591, train_acc = 0.9595, val_acc = 0.8120\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8070\n",
            "d-step 120 epoch 1 : .......... average_loss = 0.1459, train_acc = 0.9635, val_acc = 0.8060\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8080\n",
            "d-step 121 epoch 1 : .......... average_loss = 0.1429, train_acc = 0.9625, val_acc = 0.8220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8170\n",
            "d-step 122 epoch 1 : .......... average_loss = 0.1623, train_acc = 0.9560, val_acc = 0.8160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8140\n",
            "d-step 123 epoch 1 : .......... average_loss = 0.1426, train_acc = 0.9560, val_acc = 0.8120\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8140\n",
            "d-step 124 epoch 1 : .......... average_loss = 0.1212, train_acc = 0.9650, val_acc = 0.8190\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8180\n",
            "d-step 125 epoch 1 : .......... average_loss = 0.1537, train_acc = 0.9570, val_acc = 0.8270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8210\n",
            "d-step 126 epoch 1 : .......... average_loss = 0.1611, train_acc = 0.9550, val_acc = 0.8320\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8310\n",
            "d-step 127 epoch 1 : .......... average_loss = 0.1223, train_acc = 0.9700, val_acc = 0.8220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8270\n",
            "d-step 128 epoch 1 : .......... average_loss = 0.1232, train_acc = 0.9670, val_acc = 0.8130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8110\n",
            "d-step 129 epoch 1 : .......... average_loss = 0.1306, train_acc = 0.9625, val_acc = 0.8140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8210\n",
            "d-step 130 epoch 1 : .......... average_loss = 0.1238, train_acc = 0.9660, val_acc = 0.8360\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8360\n",
            "d-step 131 epoch 1 : .......... average_loss = 0.1265, train_acc = 0.9675, val_acc = 0.8160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8240\n",
            "d-step 132 epoch 1 : .......... average_loss = 0.1320, train_acc = 0.9630, val_acc = 0.8280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8330\n",
            "d-step 133 epoch 1 : .......... average_loss = 0.1357, train_acc = 0.9655, val_acc = 0.8360\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8370\n",
            "d-step 134 epoch 1 : .......... average_loss = 0.1344, train_acc = 0.9640, val_acc = 0.8280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8290\n",
            "d-step 135 epoch 1 : .......... average_loss = 0.1380, train_acc = 0.9635, val_acc = 0.8260\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8290\n",
            "d-step 136 epoch 1 : .......... average_loss = 0.1184, train_acc = 0.9655, val_acc = 0.8340\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8340\n",
            "d-step 137 epoch 1 : .......... average_loss = 0.1120, train_acc = 0.9725, val_acc = 0.8260\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8300\n",
            "d-step 138 epoch 1 : .......... average_loss = 0.1297, train_acc = 0.9685, val_acc = 0.8340\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8310\n",
            "d-step 139 epoch 1 : .......... average_loss = 0.1089, train_acc = 0.9705, val_acc = 0.8260\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8290\n",
            "d-step 140 epoch 1 : .......... average_loss = 0.1166, train_acc = 0.9660, val_acc = 0.8310\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8350\n",
            "d-step 141 epoch 1 : .......... average_loss = 0.1343, train_acc = 0.9640, val_acc = 0.8380\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8320\n",
            "d-step 142 epoch 1 : .......... average_loss = 0.1361, train_acc = 0.9625, val_acc = 0.8380\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8440\n",
            "d-step 143 epoch 1 : .......... average_loss = 0.1090, train_acc = 0.9755, val_acc = 0.8250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8220\n",
            "d-step 144 epoch 1 : .......... average_loss = 0.1269, train_acc = 0.9675, val_acc = 0.8410\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8390\n",
            "d-step 145 epoch 1 : .......... average_loss = 0.1128, train_acc = 0.9725, val_acc = 0.8450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8380\n",
            "d-step 146 epoch 1 : .......... average_loss = 0.1333, train_acc = 0.9655, val_acc = 0.8390\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8320\n",
            "d-step 147 epoch 1 : .......... average_loss = 0.1139, train_acc = 0.9680, val_acc = 0.8440\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8340\n",
            "d-step 148 epoch 1 : .......... average_loss = 0.1035, train_acc = 0.9720, val_acc = 0.8310\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8290\n",
            "d-step 149 epoch 1 : .......... average_loss = 0.1131, train_acc = 0.9680, val_acc = 0.8400\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8380\n",
            "d-step 150 epoch 1 : .......... average_loss = 0.1187, train_acc = 0.9680, val_acc = 0.8350\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8470\n",
            "d-step 151 epoch 1 : .......... average_loss = 0.1252, train_acc = 0.9650, val_acc = 0.8360\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8350\n",
            "d-step 152 epoch 1 : .......... average_loss = 0.1339, train_acc = 0.9610, val_acc = 0.8660\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8650\n",
            "d-step 153 epoch 1 : .......... average_loss = 0.1246, train_acc = 0.9660, val_acc = 0.8480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8440\n",
            "d-step 154 epoch 1 : .......... average_loss = 0.1196, train_acc = 0.9685, val_acc = 0.8500\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8530\n",
            "d-step 155 epoch 1 : .......... average_loss = 0.0789, train_acc = 0.9815, val_acc = 0.8470\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8500\n",
            "d-step 156 epoch 1 : .......... average_loss = 0.1194, train_acc = 0.9605, val_acc = 0.8530\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8420\n",
            "d-step 157 epoch 1 : .......... average_loss = 0.1015, train_acc = 0.9775, val_acc = 0.8440\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8450\n",
            "d-step 158 epoch 1 : .......... average_loss = 0.1248, train_acc = 0.9670, val_acc = 0.8400\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8420\n",
            "d-step 159 epoch 1 : .......... average_loss = 0.1055, train_acc = 0.9725, val_acc = 0.8450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8470\n",
            "d-step 160 epoch 1 : .......... average_loss = 0.1066, train_acc = 0.9705, val_acc = 0.8580\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8550\n",
            "d-step 161 epoch 1 : .......... average_loss = 0.1103, train_acc = 0.9720, val_acc = 0.8540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8510\n",
            "d-step 162 epoch 1 : .......... average_loss = 0.1171, train_acc = 0.9685, val_acc = 0.8390\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8340\n",
            "d-step 163 epoch 1 : .......... average_loss = 0.1238, train_acc = 0.9680, val_acc = 0.8340\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8460\n",
            "d-step 164 epoch 1 : .......... average_loss = 0.1065, train_acc = 0.9725, val_acc = 0.8570\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8630\n",
            "d-step 165 epoch 1 : .......... average_loss = 0.0908, train_acc = 0.9770, val_acc = 0.8550\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8560\n",
            "d-step 166 epoch 1 : .......... average_loss = 0.1129, train_acc = 0.9720, val_acc = 0.8510\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8500\n",
            "d-step 167 epoch 1 : .......... average_loss = 0.1202, train_acc = 0.9695, val_acc = 0.8620\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8650\n",
            "d-step 168 epoch 1 : .......... average_loss = 0.1278, train_acc = 0.9620, val_acc = 0.8720\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8720\n",
            "d-step 169 epoch 1 : .......... average_loss = 0.1088, train_acc = 0.9710, val_acc = 0.8490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8510\n",
            "d-step 170 epoch 1 : .......... average_loss = 0.1003, train_acc = 0.9780, val_acc = 0.8550\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8610\n",
            "d-step 171 epoch 1 : .......... average_loss = 0.1292, train_acc = 0.9680, val_acc = 0.8580\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8590\n",
            "d-step 172 epoch 1 : .......... average_loss = 0.0995, train_acc = 0.9750, val_acc = 0.8580\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8650\n",
            "d-step 173 epoch 1 : .......... average_loss = 0.0934, train_acc = 0.9760, val_acc = 0.8490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8460\n",
            "d-step 174 epoch 1 : .......... average_loss = 0.1064, train_acc = 0.9720, val_acc = 0.8590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8630\n",
            "d-step 175 epoch 1 : .......... average_loss = 0.1110, train_acc = 0.9710, val_acc = 0.8510\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8580\n",
            "d-step 176 epoch 1 : .......... average_loss = 0.1057, train_acc = 0.9715, val_acc = 0.8660\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8670\n",
            "d-step 177 epoch 1 : .......... average_loss = 0.1096, train_acc = 0.9705, val_acc = 0.8790\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8760\n",
            "d-step 178 epoch 1 : .......... average_loss = 0.0954, train_acc = 0.9750, val_acc = 0.8580\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8570\n",
            "d-step 179 epoch 1 : .......... average_loss = 0.1015, train_acc = 0.9745, val_acc = 0.8600\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8620\n",
            "d-step 180 epoch 1 : .......... average_loss = 0.1083, train_acc = 0.9730, val_acc = 0.8590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8590\n",
            "d-step 181 epoch 1 : .......... average_loss = 0.1077, train_acc = 0.9710, val_acc = 0.8640\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8580\n",
            "d-step 182 epoch 1 : .......... average_loss = 0.0736, train_acc = 0.9825, val_acc = 0.8550\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8500\n",
            "d-step 183 epoch 1 : .......... average_loss = 0.0940, train_acc = 0.9765, val_acc = 0.8590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8540\n",
            "d-step 184 epoch 1 : .......... average_loss = 0.0947, train_acc = 0.9775, val_acc = 0.8540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8520\n",
            "d-step 185 epoch 1 : .......... average_loss = 0.1090, train_acc = 0.9725, val_acc = 0.8790\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8710\n",
            "d-step 186 epoch 1 : .......... average_loss = 0.0734, train_acc = 0.9855, val_acc = 0.8680\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8660\n",
            "d-step 187 epoch 1 : .......... average_loss = 0.0853, train_acc = 0.9775, val_acc = 0.8600\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8650\n",
            "d-step 188 epoch 1 : .......... average_loss = 0.0966, train_acc = 0.9735, val_acc = 0.8670\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8690\n",
            "d-step 189 epoch 1 : .......... average_loss = 0.0999, train_acc = 0.9740, val_acc = 0.8820\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8740\n",
            "d-step 190 epoch 1 : .......... average_loss = 0.0946, train_acc = 0.9790, val_acc = 0.8650\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8700\n",
            "d-step 191 epoch 1 : .......... average_loss = 0.1042, train_acc = 0.9735, val_acc = 0.8850\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8830\n",
            "d-step 192 epoch 1 : .......... average_loss = 0.0935, train_acc = 0.9735, val_acc = 0.8770\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8730\n",
            "d-step 193 epoch 1 : .......... average_loss = 0.0798, train_acc = 0.9820, val_acc = 0.8780\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8790\n",
            "d-step 194 epoch 1 : .......... average_loss = 0.0892, train_acc = 0.9795, val_acc = 0.8800\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8800\n",
            "d-step 195 epoch 1 : .......... average_loss = 0.0982, train_acc = 0.9720, val_acc = 0.8300\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8310\n",
            "d-step 196 epoch 1 : .......... average_loss = 0.0898, train_acc = 0.9735, val_acc = 0.8540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8650\n",
            "d-step 197 epoch 1 : .......... average_loss = 0.0867, train_acc = 0.9800, val_acc = 0.8800\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8770\n",
            "d-step 198 epoch 1 : .......... average_loss = 0.0991, train_acc = 0.9735, val_acc = 0.8720\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8710\n",
            "d-step 199 epoch 1 : .......... average_loss = 0.1004, train_acc = 0.9705, val_acc = 0.8710\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8670\n",
            "d-step 200 epoch 1 : .......... average_loss = 0.0754, train_acc = 0.9815, val_acc = 0.8670\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8770\n",
            "d-step 201 epoch 1 : .......... average_loss = 0.0875, train_acc = 0.9755, val_acc = 0.8740\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8740\n",
            "d-step 202 epoch 1 : .......... average_loss = 0.0751, train_acc = 0.9815, val_acc = 0.8620\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8670\n",
            "d-step 203 epoch 1 : .......... average_loss = 0.0837, train_acc = 0.9780, val_acc = 0.8770\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8800\n",
            "d-step 204 epoch 1 : .......... average_loss = 0.0939, train_acc = 0.9765, val_acc = 0.8690\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8710\n",
            "d-step 205 epoch 1 : .......... average_loss = 0.0897, train_acc = 0.9795, val_acc = 0.8800\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8810\n",
            "d-step 206 epoch 1 : .......... average_loss = 0.1116, train_acc = 0.9680, val_acc = 0.8780\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8880\n",
            "d-step 207 epoch 1 : .......... average_loss = 0.1062, train_acc = 0.9710, val_acc = 0.8840\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8820\n",
            "d-step 208 epoch 1 : .......... average_loss = 0.0960, train_acc = 0.9750, val_acc = 0.8760\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8800\n",
            "d-step 209 epoch 1 : .......... average_loss = 0.0908, train_acc = 0.9775, val_acc = 0.8820\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8840\n",
            "d-step 210 epoch 1 : .......... average_loss = 0.0996, train_acc = 0.9755, val_acc = 0.8820\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8830\n",
            "d-step 211 epoch 1 : .......... average_loss = 0.0962, train_acc = 0.9770, val_acc = 0.8820\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8830\n",
            "d-step 212 epoch 1 : .......... average_loss = 0.0913, train_acc = 0.9780, val_acc = 0.8830\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8820\n",
            "d-step 213 epoch 1 : .......... average_loss = 0.0928, train_acc = 0.9790, val_acc = 0.8800\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8830\n",
            "d-step 214 epoch 1 : .......... average_loss = 0.0890, train_acc = 0.9790, val_acc = 0.8900\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8920\n",
            "d-step 215 epoch 1 : .......... average_loss = 0.0769, train_acc = 0.9780, val_acc = 0.8780\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8750\n",
            "d-step 216 epoch 1 : .......... average_loss = 0.0849, train_acc = 0.9765, val_acc = 0.8860\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8850\n",
            "d-step 217 epoch 1 : .......... average_loss = 0.0752, train_acc = 0.9790, val_acc = 0.8750\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8800\n",
            "d-step 218 epoch 1 : .......... average_loss = 0.0800, train_acc = 0.9800, val_acc = 0.8670\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8700\n",
            "d-step 219 epoch 1 : .......... average_loss = 0.0931, train_acc = 0.9775, val_acc = 0.8860\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8870\n",
            "d-step 220 epoch 1 : .......... average_loss = 0.0745, train_acc = 0.9830, val_acc = 0.8920\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8950\n",
            "d-step 221 epoch 1 : .......... average_loss = 0.1004, train_acc = 0.9760, val_acc = 0.9020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8940\n",
            "d-step 222 epoch 1 : .......... average_loss = 0.0829, train_acc = 0.9800, val_acc = 0.9030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8970\n",
            "d-step 223 epoch 1 : .......... average_loss = 0.0862, train_acc = 0.9810, val_acc = 0.8830\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8860\n",
            "d-step 224 epoch 1 : .......... average_loss = 0.0969, train_acc = 0.9765, val_acc = 0.9060\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9030\n",
            "d-step 225 epoch 1 : .......... average_loss = 0.0586, train_acc = 0.9875, val_acc = 0.8850\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8930\n",
            "d-step 226 epoch 1 : .......... average_loss = 0.0839, train_acc = 0.9795, val_acc = 0.8910\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9000\n",
            "d-step 227 epoch 1 : .......... average_loss = 0.0895, train_acc = 0.9775, val_acc = 0.8910\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8940\n",
            "d-step 228 epoch 1 : .......... average_loss = 0.0767, train_acc = 0.9810, val_acc = 0.8890\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8930\n",
            "d-step 229 epoch 1 : .......... average_loss = 0.1069, train_acc = 0.9705, val_acc = 0.8940\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8930\n",
            "d-step 230 epoch 1 : .......... average_loss = 0.0725, train_acc = 0.9815, val_acc = 0.9040\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9040\n",
            "d-step 231 epoch 1 : .......... average_loss = 0.0894, train_acc = 0.9765, val_acc = 0.8920\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8900\n",
            "d-step 232 epoch 1 : .......... average_loss = 0.0592, train_acc = 0.9865, val_acc = 0.8830\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8840\n",
            "d-step 233 epoch 1 : .......... average_loss = 0.0811, train_acc = 0.9775, val_acc = 0.8960\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8980\n",
            "d-step 234 epoch 1 : .......... average_loss = 0.0731, train_acc = 0.9820, val_acc = 0.8960\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8940\n",
            "d-step 235 epoch 1 : .......... average_loss = 0.0939, train_acc = 0.9790, val_acc = 0.9000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9060\n",
            "d-step 236 epoch 1 : .......... average_loss = 0.0811, train_acc = 0.9785, val_acc = 0.8880\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8920\n",
            "d-step 237 epoch 1 : .......... average_loss = 0.0846, train_acc = 0.9805, val_acc = 0.8940\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8880\n",
            "d-step 238 epoch 1 : .......... average_loss = 0.0757, train_acc = 0.9825, val_acc = 0.8970\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9020\n",
            "d-step 239 epoch 1 : .......... average_loss = 0.0842, train_acc = 0.9795, val_acc = 0.9000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8980\n",
            "d-step 240 epoch 1 : .......... average_loss = 0.0807, train_acc = 0.9800, val_acc = 0.9020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8990\n",
            "d-step 241 epoch 1 : .......... average_loss = 0.0620, train_acc = 0.9840, val_acc = 0.8960\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8920\n",
            "d-step 242 epoch 1 : .......... average_loss = 0.0828, train_acc = 0.9800, val_acc = 0.8950\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8920\n",
            "d-step 243 epoch 1 : .......... average_loss = 0.0707, train_acc = 0.9830, val_acc = 0.8950\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8860\n",
            "d-step 244 epoch 1 : .......... average_loss = 0.0805, train_acc = 0.9785, val_acc = 0.8970\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8930\n",
            "d-step 245 epoch 1 : .......... average_loss = 0.0733, train_acc = 0.9840, val_acc = 0.8940\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8900\n",
            "d-step 246 epoch 1 : .......... average_loss = 0.0656, train_acc = 0.9855, val_acc = 0.9020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9040\n",
            "d-step 247 epoch 1 : .......... average_loss = 0.0602, train_acc = 0.9855, val_acc = 0.8940\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8970\n",
            "d-step 248 epoch 1 : .......... average_loss = 0.0781, train_acc = 0.9810, val_acc = 0.9080\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9060\n",
            "d-step 249 epoch 1 : .......... average_loss = 0.0676, train_acc = 0.9830, val_acc = 0.9170\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9140\n",
            "d-step 250 epoch 1 : .......... average_loss = 0.0650, train_acc = 0.9850, val_acc = 0.8840\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8890\n",
            "d-step 251 epoch 1 : .......... average_loss = 0.0711, train_acc = 0.9835, val_acc = 0.9000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9060\n",
            "d-step 252 epoch 1 : .......... average_loss = 0.0691, train_acc = 0.9840, val_acc = 0.9070\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9020\n",
            "d-step 253 epoch 1 : .......... average_loss = 0.0894, train_acc = 0.9800, val_acc = 0.8970\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8930\n",
            "d-step 254 epoch 1 : .......... average_loss = 0.0755, train_acc = 0.9845, val_acc = 0.9110\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9120\n",
            "d-step 255 epoch 1 : .......... average_loss = 0.0715, train_acc = 0.9820, val_acc = 0.9090\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9060\n",
            "d-step 256 epoch 1 : .......... average_loss = 0.0556, train_acc = 0.9860, val_acc = 0.8980\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9000\n",
            "d-step 257 epoch 1 : .......... average_loss = 0.0760, train_acc = 0.9820, val_acc = 0.9090\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9030\n",
            "d-step 258 epoch 1 : .......... average_loss = 0.0906, train_acc = 0.9785, val_acc = 0.9020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9020\n",
            "d-step 259 epoch 1 : .......... average_loss = 0.0639, train_acc = 0.9855, val_acc = 0.8950\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9020\n",
            "d-step 260 epoch 1 : .......... average_loss = 0.0561, train_acc = 0.9880, val_acc = 0.9110\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9060\n",
            "d-step 261 epoch 1 : .......... average_loss = 0.0786, train_acc = 0.9800, val_acc = 0.9200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9230\n",
            "d-step 262 epoch 1 : .......... average_loss = 0.0689, train_acc = 0.9850, val_acc = 0.9040\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8980\n",
            "d-step 263 epoch 1 : .......... average_loss = 0.0769, train_acc = 0.9815, val_acc = 0.9120\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9070\n",
            "d-step 264 epoch 1 : .......... average_loss = 0.0776, train_acc = 0.9845, val_acc = 0.9070\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9050\n",
            "d-step 265 epoch 1 : .......... average_loss = 0.0677, train_acc = 0.9855, val_acc = 0.9110\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9090\n",
            "d-step 266 epoch 1 : .......... average_loss = 0.0580, train_acc = 0.9860, val_acc = 0.9020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9040\n",
            "d-step 267 epoch 1 : .......... average_loss = 0.0887, train_acc = 0.9800, val_acc = 0.8980\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9030\n",
            "d-step 268 epoch 1 : .......... average_loss = 0.0621, train_acc = 0.9845, val_acc = 0.9190\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9170\n",
            "d-step 269 epoch 1 : .......... average_loss = 0.0554, train_acc = 0.9865, val_acc = 0.9090\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9040\n",
            "d-step 270 epoch 1 : .......... average_loss = 0.0873, train_acc = 0.9795, val_acc = 0.9030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9060\n",
            "d-step 271 epoch 1 : .......... average_loss = 0.0659, train_acc = 0.9845, val_acc = 0.9020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8980\n",
            "d-step 272 epoch 1 : .......... average_loss = 0.0639, train_acc = 0.9840, val_acc = 0.9030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9050\n",
            "d-step 273 epoch 1 : .......... average_loss = 0.0671, train_acc = 0.9835, val_acc = 0.9060\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9030\n",
            "d-step 274 epoch 1 : .......... average_loss = 0.0635, train_acc = 0.9845, val_acc = 0.9110\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9140\n",
            "d-step 275 epoch 1 : .......... average_loss = 0.0708, train_acc = 0.9830, val_acc = 0.9130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9110\n",
            "d-step 276 epoch 1 : .......... average_loss = 0.0675, train_acc = 0.9850, val_acc = 0.9040\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9010\n",
            "d-step 277 epoch 1 : .......... average_loss = 0.0534, train_acc = 0.9875, val_acc = 0.9040\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9040\n",
            "d-step 278 epoch 1 : .......... average_loss = 0.0593, train_acc = 0.9860, val_acc = 0.9220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9170\n",
            "d-step 279 epoch 1 : .......... average_loss = 0.0773, train_acc = 0.9830, val_acc = 0.8990\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9070\n",
            "d-step 280 epoch 1 : .......... average_loss = 0.0689, train_acc = 0.9830, val_acc = 0.9040\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9050\n",
            "d-step 281 epoch 1 : .......... average_loss = 0.0761, train_acc = 0.9825, val_acc = 0.9190\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9230\n",
            "d-step 282 epoch 1 : .......... average_loss = 0.0656, train_acc = 0.9850, val_acc = 0.9160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9050\n",
            "d-step 283 epoch 1 : .......... average_loss = 0.0774, train_acc = 0.9810, val_acc = 0.9200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9230\n",
            "d-step 284 epoch 1 : .......... average_loss = 0.0712, train_acc = 0.9820, val_acc = 0.9160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9200\n",
            "d-step 285 epoch 1 : .......... average_loss = 0.0646, train_acc = 0.9860, val_acc = 0.9030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9040\n",
            "d-step 286 epoch 1 : .......... average_loss = 0.0763, train_acc = 0.9795, val_acc = 0.9160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9190\n",
            "d-step 287 epoch 1 : .......... average_loss = 0.0568, train_acc = 0.9860, val_acc = 0.9070\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9090\n",
            "d-step 288 epoch 1 : .......... average_loss = 0.0736, train_acc = 0.9825, val_acc = 0.9150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9170\n",
            "d-step 289 epoch 1 : .......... average_loss = 0.0688, train_acc = 0.9820, val_acc = 0.9110\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9130\n",
            "d-step 290 epoch 1 : .......... average_loss = 0.0633, train_acc = 0.9855, val_acc = 0.9030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9060\n",
            "d-step 291 epoch 1 : .......... average_loss = 0.0491, train_acc = 0.9890, val_acc = 0.9060\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9040\n",
            "d-step 292 epoch 1 : .......... average_loss = 0.0740, train_acc = 0.9810, val_acc = 0.9130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9090\n",
            "d-step 293 epoch 1 : .......... average_loss = 0.0635, train_acc = 0.9870, val_acc = 0.9070\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9080\n",
            "d-step 294 epoch 1 : .......... average_loss = 0.0467, train_acc = 0.9870, val_acc = 0.9210\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9170\n",
            "d-step 295 epoch 1 : .......... average_loss = 0.0543, train_acc = 0.9875, val_acc = 0.9220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9130\n",
            "d-step 296 epoch 1 : .......... average_loss = 0.0785, train_acc = 0.9825, val_acc = 0.9110\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9140\n",
            "d-step 297 epoch 1 : .......... average_loss = 0.0538, train_acc = 0.9880, val_acc = 0.9180\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9140\n",
            "d-step 298 epoch 1 : .......... average_loss = 0.0608, train_acc = 0.9855, val_acc = 0.9200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9190\n",
            "d-step 299 epoch 1 : .......... average_loss = 0.0681, train_acc = 0.9815, val_acc = 0.9140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9150\n",
            "d-step 300 epoch 1 : .......... average_loss = 0.0447, train_acc = 0.9900, val_acc = 0.9160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Znhasa7gr5"
      },
      "source": [
        "Состязательное обучение. Обучение генератора на основе обучения с подкреплением"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oELznd8Bs6-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3071ecfe-043b-4f64-8f28-bf4856c245b1"
      },
      "source": [
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "# average_train_NLL = 1.7516 average_test_NLL = 1.9832"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_train_NLL = 3.4587 average_test_NLL = 5.7914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9gy5KOOuibf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377a678a-e541-4708-98e7-72646841ec1d"
      },
      "source": [
        "# gen_optimizer = optim.Adagrad(gen.parameters(), lr=0.0005)#Adam #, lr=0.0005\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters())\n",
        "# gen_optimizer = optim.Adam(gen.parameters(), lr=0.0001)#Adam #, lr=0.0005\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters(), lr=0.001)#, lr=0.002\n",
        "\n",
        "# состязательное обучение генератора\n",
        "print('\\nStarting Adversarial Training...')\n",
        "\n",
        "for epoch in range(ADV_TRAIN_EPOCHS):# ADV_TRAIN_EPOCHS\n",
        "    print('\\n--------\\nEPOCH %d\\n--------' % (epoch+1))\n",
        "    # обучение генератора\n",
        "    print('\\nAdversarial Training Generator : ', end='')\n",
        "    train_generator_PG(gen, gen_optimizer, dis, 1)#\n",
        "\n",
        "    # тестирование nll\n",
        "    print('\\nTesting Generator : ', end='')\n",
        "    test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "\n",
        "    # обучение дискриминатора\n",
        "    print('\\nAdversarial Training Discriminator : ')\n",
        "    train_discriminator(dis, dis_optimizer, data_file_tensor_train, gen, 5, 1)#3, 1\n",
        "\n",
        "# сохранение результата обучения\n",
        "save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "            FILE_PATHS['saved_models'] + r'/' + r'seqgan_adversarial_training.pytorch')\n",
        "# epoch 3 : .......... average_train_NLL = 1.8005 average_test_NLL = 1.9824\n",
        "# average_train_NLL = 1.7340 average_test_NLL = 2.0599"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Adversarial Training...\n",
            "\n",
            "--------\n",
            "EPOCH 1\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.4626 average_test_NLL = 5.7944\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9210\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0776, train_acc = 0.9765, val_acc = 0.9210\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9150\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0508, train_acc = 0.9885, val_acc = 0.9190\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9200\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0595, train_acc = 0.9850, val_acc = 0.9250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9260\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0626, train_acc = 0.9850, val_acc = 0.9220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9230\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0594, train_acc = 0.9870, val_acc = 0.9360\n",
            "\n",
            "--------\n",
            "EPOCH 2\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.4677 average_test_NLL = 5.7976\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9370\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0484, train_acc = 0.9885, val_acc = 0.9330\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9280\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0689, train_acc = 0.9840, val_acc = 0.9420\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9420\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0555, train_acc = 0.9885, val_acc = 0.9370\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9410\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0578, train_acc = 0.9860, val_acc = 0.9430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9440\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0785, train_acc = 0.9800, val_acc = 0.9350\n",
            "\n",
            "--------\n",
            "EPOCH 3\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.4733 average_test_NLL = 5.8009\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9250\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0787, train_acc = 0.9815, val_acc = 0.9240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9310\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0557, train_acc = 0.9875, val_acc = 0.9340\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9290\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0592, train_acc = 0.9855, val_acc = 0.9280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9290\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0641, train_acc = 0.9855, val_acc = 0.9280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9280\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0829, train_acc = 0.9805, val_acc = 0.9240\n",
            "\n",
            "--------\n",
            "EPOCH 4\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.4793 average_test_NLL = 5.8041\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9260\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0554, train_acc = 0.9890, val_acc = 0.9340\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9320\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0567, train_acc = 0.9885, val_acc = 0.9300\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9320\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0580, train_acc = 0.9830, val_acc = 0.9350\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9350\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0565, train_acc = 0.9875, val_acc = 0.9300\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9360\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0732, train_acc = 0.9835, val_acc = 0.9320\n",
            "\n",
            "--------\n",
            "EPOCH 5\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.4853 average_test_NLL = 5.8071\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9450\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0535, train_acc = 0.9875, val_acc = 0.9510\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9460\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0681, train_acc = 0.9835, val_acc = 0.9490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9510\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0645, train_acc = 0.9840, val_acc = 0.9520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9510\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0513, train_acc = 0.9870, val_acc = 0.9450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9510\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0671, train_acc = 0.9840, val_acc = 0.9550\n",
            "\n",
            "--------\n",
            "EPOCH 6\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.4912 average_test_NLL = 5.8100\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9400\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0644, train_acc = 0.9865, val_acc = 0.9280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9280\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0633, train_acc = 0.9850, val_acc = 0.9320\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9300\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0622, train_acc = 0.9845, val_acc = 0.9220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9230\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0525, train_acc = 0.9875, val_acc = 0.9320\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9270\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0533, train_acc = 0.9875, val_acc = 0.9300\n",
            "\n",
            "--------\n",
            "EPOCH 7\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.4968 average_test_NLL = 5.8126\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9370\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0720, train_acc = 0.9825, val_acc = 0.9420\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9400\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0460, train_acc = 0.9905, val_acc = 0.9370\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9380\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0733, train_acc = 0.9850, val_acc = 0.9440\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9400\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0499, train_acc = 0.9895, val_acc = 0.9370\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9390\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0383, train_acc = 0.9910, val_acc = 0.9390\n",
            "\n",
            "--------\n",
            "EPOCH 8\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5021 average_test_NLL = 5.8150\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9520\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0504, train_acc = 0.9870, val_acc = 0.9640\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9520\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0648, train_acc = 0.9850, val_acc = 0.9570\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9570\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0610, train_acc = 0.9830, val_acc = 0.9580\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9590\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0663, train_acc = 0.9855, val_acc = 0.9560\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9590\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0550, train_acc = 0.9880, val_acc = 0.9510\n",
            "\n",
            "--------\n",
            "EPOCH 9\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5070 average_test_NLL = 5.8172\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9450\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0497, train_acc = 0.9875, val_acc = 0.9480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9450\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0505, train_acc = 0.9865, val_acc = 0.9430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9440\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0405, train_acc = 0.9895, val_acc = 0.9430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9420\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0429, train_acc = 0.9895, val_acc = 0.9510\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9510\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0545, train_acc = 0.9880, val_acc = 0.9420\n",
            "\n",
            "--------\n",
            "EPOCH 10\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5116 average_test_NLL = 5.8192\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9450\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0530, train_acc = 0.9890, val_acc = 0.9540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9540\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0612, train_acc = 0.9855, val_acc = 0.9460\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9480\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0672, train_acc = 0.9860, val_acc = 0.9380\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9400\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0364, train_acc = 0.9915, val_acc = 0.9500\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9440\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0618, train_acc = 0.9860, val_acc = 0.9520\n",
            "\n",
            "--------\n",
            "EPOCH 11\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5159 average_test_NLL = 5.8210\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9520\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0492, train_acc = 0.9875, val_acc = 0.9490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9470\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0422, train_acc = 0.9880, val_acc = 0.9480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9450\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0529, train_acc = 0.9875, val_acc = 0.9490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9510\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0524, train_acc = 0.9875, val_acc = 0.9450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9460\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0555, train_acc = 0.9900, val_acc = 0.9420\n",
            "\n",
            "--------\n",
            "EPOCH 12\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5197 average_test_NLL = 5.8225\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9450\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0518, train_acc = 0.9885, val_acc = 0.9340\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9430\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0559, train_acc = 0.9875, val_acc = 0.9460\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9480\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0491, train_acc = 0.9885, val_acc = 0.9490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9450\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0473, train_acc = 0.9900, val_acc = 0.9520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9490\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0504, train_acc = 0.9880, val_acc = 0.9540\n",
            "\n",
            "--------\n",
            "EPOCH 13\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5231 average_test_NLL = 5.8238\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9500\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0610, train_acc = 0.9845, val_acc = 0.9490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9510\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0566, train_acc = 0.9870, val_acc = 0.9510\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9460\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0302, train_acc = 0.9945, val_acc = 0.9470\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9450\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0468, train_acc = 0.9880, val_acc = 0.9520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9510\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0353, train_acc = 0.9915, val_acc = 0.9470\n",
            "\n",
            "--------\n",
            "EPOCH 14\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5262 average_test_NLL = 5.8251\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9450\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0366, train_acc = 0.9905, val_acc = 0.9510\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9450\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0563, train_acc = 0.9880, val_acc = 0.9470\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9480\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0482, train_acc = 0.9885, val_acc = 0.9460\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9510\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0491, train_acc = 0.9895, val_acc = 0.9500\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9450\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0421, train_acc = 0.9915, val_acc = 0.9500\n",
            "\n",
            "--------\n",
            "EPOCH 15\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5291 average_test_NLL = 5.8262\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9430\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0473, train_acc = 0.9900, val_acc = 0.9440\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9420\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0560, train_acc = 0.9850, val_acc = 0.9350\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9390\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0304, train_acc = 0.9930, val_acc = 0.9380\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9400\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0569, train_acc = 0.9845, val_acc = 0.9340\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9330\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0572, train_acc = 0.9875, val_acc = 0.9390\n",
            "\n",
            "--------\n",
            "EPOCH 16\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5317 average_test_NLL = 5.8271\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9510\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0481, train_acc = 0.9895, val_acc = 0.9450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9480\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0586, train_acc = 0.9885, val_acc = 0.9520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9520\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0373, train_acc = 0.9910, val_acc = 0.9500\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9540\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0464, train_acc = 0.9905, val_acc = 0.9510\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9470\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0425, train_acc = 0.9880, val_acc = 0.9370\n",
            "\n",
            "--------\n",
            "EPOCH 17\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5340 average_test_NLL = 5.8279\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9290\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0418, train_acc = 0.9905, val_acc = 0.9360\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9290\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0363, train_acc = 0.9900, val_acc = 0.9360\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9350\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0476, train_acc = 0.9885, val_acc = 0.9440\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9510\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0378, train_acc = 0.9915, val_acc = 0.9370\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9370\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0540, train_acc = 0.9870, val_acc = 0.9460\n",
            "\n",
            "--------\n",
            "EPOCH 18\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5359 average_test_NLL = 5.8285\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9600\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0558, train_acc = 0.9890, val_acc = 0.9520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9540\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0463, train_acc = 0.9890, val_acc = 0.9550\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9580\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0589, train_acc = 0.9845, val_acc = 0.9500\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9520\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0513, train_acc = 0.9885, val_acc = 0.9490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9510\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0538, train_acc = 0.9890, val_acc = 0.9560\n",
            "\n",
            "--------\n",
            "EPOCH 19\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5377 average_test_NLL = 5.8290\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9580\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0627, train_acc = 0.9850, val_acc = 0.9630\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9630\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0611, train_acc = 0.9870, val_acc = 0.9480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9500\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0538, train_acc = 0.9880, val_acc = 0.9580\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9610\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0463, train_acc = 0.9900, val_acc = 0.9550\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9540\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0493, train_acc = 0.9900, val_acc = 0.9570\n",
            "\n",
            "--------\n",
            "EPOCH 20\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5394 average_test_NLL = 5.8295\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9350\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0332, train_acc = 0.9915, val_acc = 0.9340\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9360\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0426, train_acc = 0.9905, val_acc = 0.9420\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9440\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0771, train_acc = 0.9825, val_acc = 0.9420\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9420\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0448, train_acc = 0.9880, val_acc = 0.9330\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9390\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0588, train_acc = 0.9845, val_acc = 0.9360\n",
            "\n",
            "--------\n",
            "EPOCH 21\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5409 average_test_NLL = 5.8299\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9610\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0443, train_acc = 0.9890, val_acc = 0.9540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9550\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0440, train_acc = 0.9895, val_acc = 0.9520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9570\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0435, train_acc = 0.9895, val_acc = 0.9610\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9640\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0459, train_acc = 0.9875, val_acc = 0.9610\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9620\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0480, train_acc = 0.9890, val_acc = 0.9620\n",
            "\n",
            "--------\n",
            "EPOCH 22\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5421 average_test_NLL = 5.8303\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9570\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0373, train_acc = 0.9905, val_acc = 0.9540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9550\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0308, train_acc = 0.9940, val_acc = 0.9630\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9600\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0568, train_acc = 0.9870, val_acc = 0.9630\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9640\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0361, train_acc = 0.9910, val_acc = 0.9590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9520\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0414, train_acc = 0.9910, val_acc = 0.9570\n",
            "\n",
            "--------\n",
            "EPOCH 23\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5433 average_test_NLL = 5.8305\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9610\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0628, train_acc = 0.9875, val_acc = 0.9650\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9600\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0364, train_acc = 0.9905, val_acc = 0.9670\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9650\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0611, train_acc = 0.9845, val_acc = 0.9690\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9670\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0448, train_acc = 0.9880, val_acc = 0.9640\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9730\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0483, train_acc = 0.9900, val_acc = 0.9620\n",
            "\n",
            "--------\n",
            "EPOCH 24\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5444 average_test_NLL = 5.8307\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9470\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0415, train_acc = 0.9895, val_acc = 0.9550\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9530\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0351, train_acc = 0.9925, val_acc = 0.9480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9490\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0290, train_acc = 0.9930, val_acc = 0.9460\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9470\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0611, train_acc = 0.9870, val_acc = 0.9520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9530\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0307, train_acc = 0.9930, val_acc = 0.9510\n",
            "\n",
            "--------\n",
            "EPOCH 25\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 3.5454 average_test_NLL = 5.8308\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9490\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.0536, train_acc = 0.9865, val_acc = 0.9430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9450\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.0690, train_acc = 0.9850, val_acc = 0.9550\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9570\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.0419, train_acc = 0.9900, val_acc = 0.9500\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9490\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.0340, train_acc = 0.9935, val_acc = 0.9460\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.9490\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.0283, train_acc = 0.9940, val_acc = 0.9430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs3-xXxc3rQ6"
      },
      "source": [
        "Тестирование генератора на обучающей выборке после состязательного обучения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWz3XBxE3nOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc3d455-7354-4141-c122-fcdb22c8cd83"
      },
      "source": [
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_train_NLL = 3.5454 average_test_NLL = 5.8308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF9S-MHOJm7d"
      },
      "source": [
        "Генерация примеров текстов на основе SeqGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLUxNkP7LhHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc16302-6a12-44b2-a768-e84858f86988"
      },
      "source": [
        "# примеры сгенерированных текстов\n",
        "print(\"Примеры генерируемых текстов на основе SeqGAN\")\n",
        "degree = 1\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tПример: \", line, ' '*(100-len(line)), '\\tОценка: ', bleu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Примеры генерируемых текстов на основе SeqGAN\n",
            "Degree: 1\n",
            "# 0 \tПример:  in jesse writes face off with 25 opportunity in a remote village while dealing with an heiress and karaoke when she must his help  \tОценка:  [0.6313087395543334, 0.4169080726689162, 0.2423680701003884, 0.11152553740468045]\n",
            "# 1 \tПример:  a new professor reunites in spanish business murders , the director and death of gender sides .         \tОценка:  [0.6915640748081247, 0.5338837915749063, 0.4362874590298468, 0.37327094197706856]\n",
            "# 2 \tПример:  when his eyes takes his death , she 's forced to return to her , two sons on the autism kingdom to his true  \tОценка:  [0.7801894976054939, 0.30245388888833086, 0.10713701843513149, 0.05804243793890311]\n",
            "# 3 \tПример:  a engaged village slave artist who shows him to korea and demonic protection in the gang to beijing .       \tОценка:  [0.5646597025732799, 0.38702317094861327, 0.30166728533047465, 0.24189259416605804]\n",
            "# 4 \tПример:  a quiet love comedian raised by an eccentric friendly score , family , with a loved of abe defend their own family love in  \tОценка:  [0.586688076025689, 0.25010974540478953, 0.09290586622696888, 0.051787925002622526]\n",
            "# 5 \tПример:  tech demon when she navigates an unprecedented experiment that is the law , he – fought by his discussions if he shatters tracking the  \tОценка:  [0.5400617248673217, 0.10985539057463595, 0.05012578715739066, 0.03161134433147459]\n",
            "# 6 \tПример:  combat love , sexual egyptian breaks with british network masha horrors , but his fiancée 's platoon on scary deaths and daughter share nothing  \tОценка:  [0.45643546458763845, 0.21156574936786715, 0.08194627122009988, 0.04684005089379953]\n",
            "# 7 \tПример:  a young man manage a carlos promise to counter in the novel .                                         \tОценка:  [0.7554152327780024, 0.6583353265356829, 0.5913453331938264, 0.5468710547571946]\n",
            "# 8 \tПример:  four korean women built a classmate channel to kill an aristocrat from spain to build a woman who 's disappearance .     \tОценка:  [0.6313087395543334, 0.4169080726689162, 0.2423680701003884, 0.11152553740468045]\n",
            "# 9 \tПример:  a burned-out accused of politeness to heart to stop a new bicycle boss orchestrates a peek .          \tОценка:  [0.6313087395543334, 0.4772406086195678, 0.4010889714538991, 0.34897842284302366]\n",
            "# 10 \tПример:  help , resonating , who insists it into a again must rely finds himself mansi 's life .               \tОценка:  [0.659380473395787, 0.49128508310682906, 0.40990938410517924, 0.35510459149943635]\n",
            "# 11 \tПример:  moody mississippi , history and decorum , passion and her human , the line between them are better with the way .    \tОценка:  [0.5989120571285179, 0.3657139799064148, 0.2196854772318462, 0.10309440089933594]\n",
            "# 12 \tПример:  after waking up to meet the rugrats kind of his wife , or her own but when their taking kidnapping new dream stash of  \tОценка:  [0.719802710490163, 0.41340447784296236, 0.13543364238447214, 0.07001244552774741]\n",
            "# 13 \tПример:  a couple 's sex worker and staying hayley to protect his powers and ready to a help , his musician and an elite teacher  \tОценка:  [0.5646597025732799, 0.3071804943499485, 0.10839029606398054, 0.058584984978893126]\n",
            "# 14 \tПример:  a disillusioned child accidentally leaves a burglar by the rush to escape out of a dragon prize when he finds her sights on his  \tОценка:  [0.7071067811865476, 0.2832581674713524, 0.10199573389218783, 0.05580326458287663]\n",
            "# 15 \tПример:  when one of the formula his office in a glimpse to cook up a beginning with a rare entrepreneur .      \tОценка:  [0.6621221919717306, 0.4635976266066475, 0.31211064283932943, 0.21639183184561958]\n",
            "# 16 \tПример:  between the trail of his longtime despite africa , friends , volunteers , unaware hunts in in human connection .      \tОценка:  [0.6770032003863301, 0.43679023236814946, 0.2984745896009823, 0.20879490260121242]\n",
            "# 17 \tПример:  an heiress on a private soul land , who run the help of his 8-year-old girlfriend ’ won , are decades for a chain  \tОценка:  [0.5989120571285179, 0.31948058852720734, 0.19850823739068116, 0.09506416269874665]\n",
            "# 18 \tПример:  six friends mean harold 's ok to the mystery job as he secretly n't be intergalactic prince who shortly them by missing while –  \tОценка:  [0.47776654295295456, 0.10123629955117001, 0.04714627368490469, 0.030098988375222294]\n",
            "# 19 \tПример:  in fire , a spoiled songbird galvanizes college invades – but when she confronts the door to ring it 's been joyful to be  \tОценка:  [0.6167939547439611, 0.25859443748893596, 0.09525977696807739, 0.05283499238396493]\n",
            "# 20 \tПример:  after tangled a dancer , yearning they get in the world of adolescence and evil , a glamorous young girl agrees to hong their  \tОценка:  [0.5516772843673705, 0.30245388888833075, 0.19051955393615475, 0.0919910647632142]\n",
            "# 21 \tПример:  raised in love , a teenage girl gets a `` soccer '' spoof .                                           \tОценка:  [0.8660254037844387, 0.7423464047399292, 0.6283080589773311, 0.5589226545728201]\n",
            "# 22 \tПример:  comic bert kreischer riffs herself in this stand-up comedy set , how traffic looks to grant even absent as spies with influential through interviews  \tОценка:  [0.3611575592573076, 0.18099097209777185, 0.07289334177359764, 0.0426524801468968]\n",
            "# 23 \tПример:  on a life of aristocrats with a disgraced friend who learns the three-year , or powers he is accused of atlatan back in a  \tОценка:  [0.6621221919717306, 0.1258397564672672, 0.05550199298151917, 0.034295794119631254]\n",
            "# 24 \tПример:  this miniseries stars follows new loss , a peaceful murder and falls for an evil ring in this docuseries , heartbreak from its school  \tОценка:  [0.6313087395543334, 0.26263562831333453, 0.09637411586929977, 0.05332886324369671]\n",
            "# 25 \tПример:  based on life 's lives talk for all kids ' days mr. miyagi .                                          \tОценка:  [0.7359800721939872, 0.605132734204158, 0.539020965801877, 0.4944223963074001]\n",
            "# 26 \tПример:  the insatiable between american tennis 's most popular off-broadway .                                 \tОценка:  [0.7905694150420949, 0.7174641902061782, 0.6777829816992624, 0.6500474603943323]\n",
            "# 27 \tПример:  this adrenaline-rush retelling of the legendary role club , survivors , skits and retiree irs children and must put her meteoric deal in this  \tОценка:  [0.3611575592573076, 0.18099097209777185, 0.07289334177359764, 0.0426524801468968]\n",
            "# 28 \tПример:  seeking to make the law of a new dome and hilarious .                                                 \tОценка:  [0.8597269536210951, 0.7387427246638507, 0.6619346095470585, 0.6127658785777553]\n",
            "# 29 \tПример:  when a businessman 's maddy named presence returns to stay on gotham turning 524 policies parenting .         \tОценка:  [0.6313087395543334, 0.4772406086195678, 0.4010889714538991, 0.34897842284302366]\n",
            "# 30 \tПример:  while triggers a dark academic of leader – but threatens a serious discovers that was a reluctant turn when they 're a heart starts  \tОценка:  [0.5516772843673705, 0.24005781069660462, 0.0900911347430732, 0.05052887704279243]\n",
            "# 31 \tПример:  after hitting with his friends jon , a homicide detective takes the underground terrorist looking for the world 's dynamic .     \tОценка:  [0.6313087395543334, 0.4169080726689162, 0.2423680701003884, 0.11152553740468045]\n",
            "# 32 \tПример:  the backdrop of marseille brain depression by entering the wicked man he once outback , and rise to assist their father and a winning  \tОценка:  [0.42562826537937426, 0.09373017196439742, 0.04449945957170705, 0.02873940616731871]\n",
            "# 33 \tПример:  when his son for a guardian of guru bandleader , disappointment , romantic turns begins draws who have been bear when a megachurch and  \tОценка:  [0.4777665429529547, 0.2181069956434999, 0.08383924775392589, 0.047703681775855995]\n",
            "# 34 \tПример:  in this stand-up `` inspiring documentary , featuring which activist stories against an tournament items as they 'll have lots of control , sleepovers  \tОценка:  [0.5383819020581655, 0.2975747471548894, 0.10583814787289994, 0.057478812334637426]\n",
            "# 35 \tПример:  when bheem ’ s found leader , clawd of his friends accidentally building decades into one again and learning for humanity — the raunchiest  \tОценка:  [0.48900964692182575, 0.22151546799151528, 0.08481999049965716, 0.04814958812064739]\n",
            "# 36 \tПример:  after a millionaire to bring his sky , adventure with reveals the earth to win them — but when she lands a bond with  \tОценка:  [0.5400617248673217, 0.10985539057463595, 0.05012578715739066, 0.03161134433147459]\n",
            "# 37 \tПример:  in this documentary , this uplifting comic adaptation of the attention of bollywood south , a young architect and his brother 's wife visits  \tОценка:  [0.719802710490163, 0.4901452064286144, 0.2736457742926551, 0.12289805159320322]\n",
            "# 38 \tПример:  when a legendary doctor inexplicably to a local politician and his secret old college , winston crew may be called women – and a  \tОценка:  [0.6313087395543334, 0.26263562831333453, 0.09637411586929977, 0.05332886324369671]\n",
            "# 39 \tПример:  now , she must solve a creative family reflects on an prep school , michiru , it 's lily to pursue her .   \tОценка:  [0.6756639246921762, 0.43621399128699967, 0.14100024578768863, 0.07230526075120511]\n",
            "# 40 \tПример:  it 's may destroy her artistic , unaware a sweet plot to save spanish thierry .                       \tОценка:  [0.6756639246921762, 0.5256688883126817, 0.45135389487255656, 0.4010529888893683]\n",
            "# 41 \tПример:  when a prestigious prep school `` saturday '' known as a brutal offensive money for the bureaucracy .        \tОценка:  [0.719802710490163, 0.4901452064286144, 0.3869935652907597, 0.32017045037625635]\n",
            "# 42 \tПример:  two rebellious young men who live tiny ethic for a friend , regret and amazing tenants .              \tОценка:  [0.6167939547439611, 0.469897277552989, 0.3964513253420688, 0.3457465843369273]\n",
            "# 43 \tПример:  this stylish of navarro `` kids '' .                                                                  \tОценка:  [0.7985494095046904, 0.7575722441646456, 0.7337451206367, 0.7161744979977512]\n",
            "# 44 \tПример:  a talented detective whose life football aunt while preparing for unemployed disasters .              \tОценка:  [0.7223151185146152, 0.618980417705646, 0.5646293974770982, 0.5270147702712498]\n",
            "# 45 \tПример:  in medicine after speaking , his acting wife and their engagement : rock formula the case , widowed woman is diagnosed with his village  \tОценка:  [0.5989120571285179, 0.11769765513384006, 0.05278627722123209, 0.03294661707174903]\n",
            "# 46 \tПример:  scene by hidden challenges , history and prank in 1827 the city of the memories of his father and torture , four very pain  \tОценка:  [0.5851421232041205, 0.3145647207478774, 0.11033865523442747, 0.05942595232175673]\n",
            "# 47 \tПример:  a prestigious bus leaves behind a con officer on the grisly staff of india and try to survive when they confront a group of  \tОценка:  [0.6770032003863301, 0.3466806371753174, 0.11868405219520975, 0.0629952630233744]\n",
            "# 48 \tПример:  the police , unearthing a musical of stand-up ray chinese reveals faith for control of genital and form flee under complications of sex ,  \tОценка:  [0.5107539184552492, 0.10584416257405499, 0.048746715608426264, 0.03091365021588745]\n",
            "# 49 \tПример:  a corrupt student evade on turning their prey to find their child soon in sweden yet .                \tОценка:  [0.6770032003863301, 0.5263632998046983, 0.43167001068522526, 0.37010717248715336]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ZUtKiv7n88"
      },
      "source": [
        "Оценка качества генерации на основе SeqGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tets0DMEuDkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d632b19-f536-45c8-91fa-933ea506f500"
      },
      "source": [
        "print(\"Оценка качества генерации текстов на основе BLEU, после обучения с помощью SeqGAN\")\n",
        "degree = 1\n",
        "print(\"Degree:\", degree)\n",
        "# проверка качества обучения\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оценка качества генерации текстов на основе BLEU, после обучения с помощью SeqGAN\n",
            "Degree: 1\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.6092547022852403\n",
            "2 200 0.6205699445641378\n",
            "2 300 0.6207494020121411\n",
            "2 400 0.623373852981553\n",
            "2 500 0.6303386721629859\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.6303386721629859 \n",
            "\n",
            "3 100 0.36357426141964105\n",
            "3 200 0.3792089713898284\n",
            "3 300 0.38303278234081245\n",
            "3 400 0.3847275959367494\n",
            "3 500 0.3938521511328785\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.3938521511328785 \n",
            "\n",
            "4 100 0.25206721888454864\n",
            "4 200 0.26947934729175205\n",
            "4 300 0.27363160716197876\n",
            "4 400 0.275768289431875\n",
            "4 500 0.2834170040187484\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.2834170040187484 \n",
            "\n",
            "5 100 0.20007553907992942\n",
            "5 200 0.2190419075984661\n",
            "5 300 0.222988038605337\n",
            "5 400 0.2261766857827814\n",
            "5 500 0.23296601500720862\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.23296601500720862 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6303386721629859,\n",
              " 0.3938521511328785,\n",
              " 0.2834170040187484,\n",
              " 0.23296601500720862]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM: [0.604328182451673,\n",
        " 0.3626909506096581,\n",
        " 0.2537040848961532,\n",
        " 0.20767160383787964]\n",
        "\n",
        " SeqGAN: [0.6303386721629859,\n",
        " 0.3938521511328785,\n",
        " 0.2834170040187484,\n",
        " 0.23296601500720862]"
      ],
      "metadata": {
        "id": "3eMYvW3QiZre"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhrWW-2bKH9E"
      },
      "source": [
        "Загрузка сохраненной модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHsreqY23P-T"
      },
      "source": [
        "# загрузка моделей\n",
        "[data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "VOCAB_SIZE, MAX_SEQ_LEN, GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, DIS_EMBEDDING_DIM,\n",
        " DIS_HIDDEN_DIM] = load_models(FILE_PATHS['saved_models'] + r'/' + r'seqgan_adversarial_training.pytorch')#[seqgan_mle, seqgan_pretraining_dis, seqgan_adversarial_training]\n",
        "\n",
        "if(CUDA):\n",
        "  gen = gen.cuda()\n",
        "  dis = dis.cuda()\n",
        "  data_file_tensor_train = torch.tensor(data_file_tensor_train).cuda()\n",
        "  data_file_tensor_test = torch.tensor(data_file_test).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}